---
title: "9. Pretraining to Post-Training"
titleKr: "9. 사전학습에서 후속학습으로"
chapter: 9
timestamp: "59:23"
sourceUrl: "https://www.youtube.com/watch?v=7xTGNNLPyMI&t=3563s"
translatedAt: "2026-01-10"
---

# 9. 사전학습에서 후속학습으로

[영상 바로가기 (59:23)](https://www.youtube.com/watch?v=7xTGNNLPyMI&t=3563s)

## 요약

사전학습으로 만들어진 베이스 모델은 인터넷 문서를 시뮬레이션할 뿐, 사용자의 질문에 직접 답변하지 못합니다. 후속학습 단계에서 이 베이스 모델을 대화가 가능한 어시스턴트로 변환합니다. ChatGPT 같은 대화형 AI를 만드는 핵심 과정으로, 계산 비용은 사전학습보다 훨씬 적지만 모델의 실용성을 결정짓는 중요한 단계입니다.

**핵심 개념:**
- **베이스 모델(Base Model)**: 인터넷 텍스트에서 사전학습된 모델로, 문서를 시뮬레이션할 수 있지만 직접 대화는 불가능
- **후속학습(Post-Training)**: 베이스 모델을 어시스턴트로 변환하는 추가 학습 단계
- **어시스턴트 페르소나**: 질문에 답하고 사용자와 대화할 수 있는 AI의 성격
- **계산 효율성**: 후속학습은 사전학습 대비 훨씬 적은 계산 자원으로 수행 가능
- **대화 형식**: 인간-어시스턴트 턴 구조로 모델의 응답 방식을 정의

---

## 전체 번역

자, 여기서 한 발 물러나서 지금까지 다룬 내용을 정리해보겠습니다. 우리는 ChatGPT 같은 LLM 어시스턴트를 학습시키고 싶습니다. 첫 번째 단계인 사전학습에 대해 이야기했는데, 핵심은 이렇습니다. 인터넷 문서를 가져와서 토큰이라는 작은 텍스트 조각의 원자 단위로 쪼갠 다음, 신경망을 사용해 토큰 시퀀스를 예측합니다. 이 전체 단계의 결과물이 바로 베이스 모델입니다. 이것은 곧 신경망의 파라미터 설정값입니다. 이 베이스 모델은 기본적으로 토큰 수준에서 인터넷 문서를 시뮬레이션하는 것입니다. 인터넷 문서와 동일한 통계적 특성을 가진 토큰 시퀀스를 생성할 수 있죠. 일부 애플리케이션에서 사용할 수 있다는 것을 봤지만, 실제로는 더 나은 것이 필요합니다. 우리는 어시스턴트를 원합니다. 질문을 할 수 있고, 모델이 답변을 주기를 원하죠. 그래서 이제 두 번째 단계인 후속학습 단계로 넘어가야 합니다. 베이스 모델, 즉 인터넷 문서 시뮬레이터를 가져와서 후속학습에 넘깁니다.

이제 모델의 후속학습이라 불리는 것을 수행하는 몇 가지 방법에 대해 논의하겠습니다. 후속학습의 이러한 단계들은 계산 비용이 훨씬 적습니다. 대규모 데이터 센터의 모든 계산 작업, 무거운 컴퓨팅, 수백만 달러는 모두 사전학습 단계에 들어갑니다. 하지만 이제 비용은 조금 적지만 여전히 매우 중요한 후속학습 단계로 들어갑니다. 여기서 LLM 모델을 어시스턴트로 바꾸죠. 그럼 모델이 인터넷 문서를 샘플링하는 대신 질문에 답변하도록 어떻게 만들 수 있는지 살펴보겠습니다.

다시 말해, 우리가 하고 싶은 것은 대화에 대해 생각하기 시작하는 것입니다. 이 대화들은 여러 턴으로 이루어질 수 있습니다. 가장 간단한 경우는 인간과 어시스턴트 사이의 대화입니다. 예를 들어, 대화가 이렇게 생겼다고 상상할 수 있습니다. 인간이 "2 더하기 2는 뭐야?"라고 물으면, 어시스턴트는 "2 더하기 2는 4입니다"라고 응답해야 합니다. 인간이 후속 질문으로 "만약 + 대신 *였다면?"이라고 물으면, 어시스턴트는 "2 곱하기 2는 4입니다"처럼 응답할 수 있습니다. 이런 식으로 대화가 이어집니다.

---
