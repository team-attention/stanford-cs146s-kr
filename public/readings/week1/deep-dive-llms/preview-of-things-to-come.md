---
title: "21. Preview of Things to Come"
titleKr: "21. 앞으로의 전망"
chapter: 21
timestamp: "3:09:39"
sourceUrl: "https://www.youtube.com/watch?v=7xTGNNLPyMI&t=11379s"
translatedAt: "2026-01-10"
---

# 21. 앞으로의 전망

[영상 바로가기 (3:09:39)](https://www.youtube.com/watch?v=7xTGNNLPyMI&t=11379s)

## 요약

LLM의 미래 발전 방향입니다.

## 핵심 포인트

- 멀티모달: 이미지, 오디오, 비디오
- 에이전트: 장시간 자율 작업
- 컴퓨터 사용: 키보드/마우스 제어

---

## 전체 번역

이 모든 것의 시작을 이미 보고 있지만, 이것은 모두 언어 모델 내부에서 기본적으로 이루어질 것이고, 자연스러운 대화를 가능하게 할 것입니다. 대략적으로 이것이 위에서 다룬 모든 것과 실제로 다르지 않은 이유는 기본적으로 오디오와 이미지를 토큰화하고 위에서 이야기한 것과 정확히 같은 접근법을 적용할 수 있기 때문입니다. 근본적인 변화가 아니라, 토큰을 몇 개 추가해야 하는 것입니다. 예를 들어 오디오를 토큰화하기 위해 오디오 신호의 스펙트로그램 조각을 보고 토큰화하고, 갑자기 오디오를 나타내는 토큰을 더 추가하고 컨텍스트 윈도우에 넣고 위와 같이 훈련합니다. 이미지도 마찬가지로 패치를 사용할 수 있고, 패치를 별도로 토큰화합니다. 이미지가 무엇인가? 이미지는 그냥 토큰의 시퀀스입니다. 이것은 실제로 작동하고 이 방향으로 많은 초기 작업이 있습니다.

오디오, 이미지, 텍스트를 나타내는 토큰 스트림을 만들고 그것들을 섞어서 단일 모델에서 동시에 처리할 수 있습니다. 이것이 멀티모달리티의 한 예입니다. 둘째로 사람들이 매우 관심을 가지는 것은 현재 대부분의 작업이 개별 작업을 모델에 은쟁반에 담아 주는 것입니다. "이 작업을 해주세요"라고 하면 모델이 이 작은 작업을 합니다. 하지만 작업을 일관되게 조직하여 직무를 수행하는 것은 여전히 우리에게 달려 있고, 모델들은 아직 긴 시간에 걸쳐 일관된 오류 수정 방식으로 이것을 할 수 있는 능력에 도달하지 않았습니다.

더 긴 직무를 수행하기 위해 작업을 완전히 연결할 수 없지만, 점점 가까워지고 있고 시간이 지나면서 개선되고 있습니다. 아마 여기서 일어날 일은 시간에 걸쳐 작업을 수행하는 에이전트라고 불리는 것을 보기 시작할 것입니다. 그들을 감독하고 작업을 지켜보고 가끔 진행 상황을 보고받습니다. 몇 초의 응답이 아니라 수십 초 또는 심지어 몇 분 또는 몇 시간이 걸리는 더 오래 실행되는 에이전트 작업을 볼 것입니다. 하지만 위에서 이야기했듯이 이 모델들은 완벽하지 않으므로, 이 모든 것은 감독이 필요합니다. 예를 들어 공장에서 사람들은 자동화를 위한 인간 대 로봇 비율에 대해 이야기합니다.

디지털 공간에서도 비슷한 것을 볼 것 같습니다. 인간 대 에이전트 비율에 대해 이야기하게 되고, 디지털 영역에서 인간이 에이전트 작업의 감독자가 될 것입니다. 다음으로 모든 것이 훨씬 더 만연하고 보이지 않게 될 것입니다. 도구에 통합되고 어디에나 있게 됩니다. 그리고 컴퓨터 사용이 있는데, 지금 이 모델들은 당신을 대신해서 행동을 취할 수 없지만, 이것은 별개의 요점입니다. ChatGPT가 오퍼레이터를 출시한 것을 보셨다면, 그것이 초기 예시인데, 실제로 모델에게 키보드와 마우스 동작을 당신을 대신해서 수행하도록 제어권을 넘겨줄 수 있습니다.

매우 흥미롭다고 생각합니다. 마지막 요점은 이 분야에서 아직 해야 할 연구가 많다는 일반적인 코멘트입니다. 한 예시는 테스트 시간 훈련 같은 것입니다. 위에서 이야기하고 다룬 모든 것은 두 가지 주요 단계가 있다는 것을 기억하세요. 첫째는 훈련 단계로, 작업을 잘 수행하도록 모델의 매개변수를 조정합니다. 매개변수를 얻으면 고정하고 추론을 위해 모델을 배포합니다. 그때부터 모델은 고정되고, 더 이상 변하지 않고, 테스트 시간에 하는 모든 것에서 배우지 않습니다. 고정된 매개변수 수이고, 변하는 유일한 것은 컨텍스트 윈도우 안의 토큰입니다.

모델이 테스트 시간에 접근할 수 있는 유일한 유형의 학습 또는 테스트 시간 학습은 동적으로 조정 가능한 컨텍스트 윈도우의 인컨텍스트 학습입니다. 하지만 이것은 실제로 무엇을 하느냐에 따라 실제로 배울 수 있는 인간과 여전히 다르다고 생각합니다. 특히 잘 때, 뇌가 매개변수를 업데이트하거나 그런 것 같습니다. 현재 이 모델들과 도구에는 그것에 대한 동등물이 없습니다. 탐구해야 할 더 복잡한 아이디어가 많다고 생각하고, 특히 컨텍스트 윈도우가 유한하고 귀중한 자원이기 때문에 필요할 것입니다.

특히 매우 오래 실행되는 멀티모달 작업을 다루기 시작하고 비디오를 넣으면, 이 토큰 윈도우는 매우 크게 자라기 시작할 것입니다. 수천이나 수십만이 아니라 그것을 훨씬 넘어서요. 지금 사용할 수 있는 유일한 트릭은 컨텍스트 윈도우를 더 길게 만드는 것이지만, 그 접근법 자체는 시간이 지나면서 멀티모달인 실제로 오래 실행되는 작업으로 확장되지 않을 것입니다. 새로운 아이디어가 필요하다고 생각합니다. 매우 긴 컨텍스트가 필요한 이런 작업들의 일부 경우에서요. 이것들이 파이프라인에서 기대할 수 있는 몇 가지 예시입니다.

---
