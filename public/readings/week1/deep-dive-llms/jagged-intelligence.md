---
title: "15. Jagged Intelligence"
titleKr: "15. 들쭉날쭉한 지능"
chapter: 15
timestamp: "2:04:53"
sourceUrl: "https://www.youtube.com/watch?v=7xTGNNLPyMI&t=7493s"
translatedAt: "2026-01-10"
---

# 15. 들쭉날쭉한 지능

[영상 바로가기 (2:04:53)](https://www.youtube.com/watch?v=7xTGNNLPyMI&t=7493s)

## 요약

LLM의 능력은 "들쭉날쭉한 지능(Jagged Intelligence)"으로 특징지어집니다. 수학 올림피아드 문제를 풀 수 있으면서도 "9.11 vs 9.9 중 어느 것이 크냐"라는 초등 문제에서 실패하기도 합니다. 이러한 예측 불가능한 실패는 학습 데이터의 특성(예: 성경 구절 패턴)에서 비롯될 수 있습니다. LLM은 마법 같은 도구이지만 완전히 신뢰할 수 없는 확률적 시스템이므로, 결과를 복사 붙여넣기하지 말고 검증하며 사용해야 합니다.

**핵심 개념:**
- **들쭉날쭉한 지능**: 어떤 영역에서는 뛰어나지만 다른 영역에서는 기본적인 실수를 하는 불균일한 능력
- **9.11 vs 9.9 문제**: 성경 구절 패턴(9장 11절)이 수치 비교를 방해하는 것으로 추정되는 사례
- **스위스 치즈 같은 능력**: 능력에 예상치 못한 구멍이 있어 어디서 실패할지 예측 어려움
- **확률적 시스템**: 결정론적이 아니라 통계적으로 작동하므로 완전한 신뢰 불가
- **도구로서의 사용**: 결과를 그대로 복사하지 말고 검증하며 활용해야 함

---

## 전체 번역

요점을 말하고 싶습니다. 여기저기 들쭉날쭉한 경계가 있습니다. 몇 가지를 논의했고 몇 가지는 이해가 됩니다. 하지만 일부는 그렇게 이해가 되지 않고 이 모델들이 어떻게 작동하는지 깊이 이해해도 머리를 긁적이게 됩니다. 최근의 좋은 예시는 다음입니다. 모델은 이런 매우 간단한 질문을 잘 못합니다. 이것은 많은 사람들에게 충격적입니다. 이 수학 문제들은 복잡한 수학 문제를 풀 수 있고, 제가 할 수 있는 것보다 훨씬 더 잘 PhD 수준의 물리, 화학, 생물 질문에 답할 수 있지만 때때로 이런 초간단 문제에서 실패합니다. 여기 갑니다. 9.11이 9.9보다 크다고 하고 어떤 방식으로 정당화하지만 분명히, 그런 다음 끝에서 실제로 결정을 뒤집습니다. 이것이 매우 재현 가능하다고 생각하지 않습니다. 때때로 답을 뒤집고 때때로 맞고 때때로 틀리고. 다시 해봅시다.

더 크게 보일 수 있지만, 여기서 끝에서 자기 자신을 수정하지도 않습니다. 여러 번 물으면 때때로 맞기도 합니다. 하지만 모델이 올림피아드 수준 문제에서 그렇게 잘할 수 있는데 이런 매우 간단한 문제에서 실패하는 것은 어떻게 가능할까요? 이것은 언급했듯이 약간 머리를 긁적이게 합니다. 많은 사람들이 이것을 깊이 연구했고 논문을 실제로 읽지는 않았지만 이 팀에게서 들은 것은 신경망 내부의 활성화를 조사하면, 어떤 특성이 켜지거나 꺼지는지, 어떤 뉴런이 켜지거나 꺼지는지 보면, 신경망 내부의 많은 뉴런이 보통 성경 구절과 관련된 것들이 켜진다고 합니다. 모델이 이것이 거의 성경 구절 표시처럼 보인다고 상기되는 것 같습니다. 성경 구절 설정에서 9.11이 9.9 이후에 올 것입니다.

기본적으로 모델이 성경 구절에서 9.11이 더 클 것이라는 것을 인지적으로 매우 산만하게 찾습니다. 여기서 수학으로 정당화하고 답에 도달하려 해도 여전히 여기서 틀린 답이 나옵니다. 기본적으로 완전히 이해가 되지 않고 완전히 이해되지 않습니다. 이런 몇 가지 들쭉날쭉한 문제가 있습니다. 그래서 이것을 있는 그대로 취급하세요. 정말 마법 같지만 완전히 신뢰할 수도 없는 확률적 시스템입니다. 문제에 풀어놓고 결과를 복사 붙여넣기하는 것이 아니라 도구로 사용하세요.

---
