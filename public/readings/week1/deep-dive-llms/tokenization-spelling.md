---
title: "14. Tokenization Revisited: Models Struggle with Spelling"
titleKr: "14. 토큰화 재방문: 철자 문제"
chapter: 14
timestamp: "2:01:11"
sourceUrl: "https://www.youtube.com/watch?v=7xTGNNLPyMI&t=7271s"
translatedAt: "2026-01-10"
---

# 14. 토큰화 재방문: 철자 문제

[영상 바로가기 (2:01:11)](https://www.youtube.com/watch?v=7xTGNNLPyMI&t=7271s)

## 요약

LLM은 문자가 아닌 토큰 단위로 텍스트를 처리하기 때문에 철자 관련 작업에 구조적 한계가 있습니다. "ubiquitous"는 우리 눈에는 10개의 개별 문자이지만, 모델에게는 3개의 토큰 덩어리로 보입니다. 이 때문에 "strawberry에서 r이 몇 개야?"라는 간단한 질문도 모델에게는 어렵습니다. 철자 조작이 필요한 작업은 Python 같은 코드 도구를 사용하면 정확한 결과를 얻을 수 있습니다.

**핵심 개념:**
- **토큰 vs 문자**: 모델은 개별 문자가 아닌 토큰(작은 텍스트 조각) 단위로 세계를 인식
- **철자 작업의 한계**: 문자 수 세기, n번째 문자 추출 등의 작업에서 빈번한 실패
- **strawberry 문제**: "r이 몇 개?" 질문이 바이럴 - 문자 인식과 세기 능력의 결합 문제
- **구조적 원인**: 효율성을 위해 토큰화를 사용하지만 문자 수준 작업에서 약점 발생
- **도구 기반 우회**: Python 인터프리터로 문자열을 조작하면 정확한 결과 획득 가능

---

## 전체 번역

그 이유는 모델이 문자를 보지 않고 토큰을 보기 때문입니다. 그들의 전체 세계는 토큰에 관한 것이고, 토큰은 이 작은 텍스트 조각들입니다. 그래서 우리 눈이 보는 것처럼 문자를 보지 않습니다. 매우 간단한 문자 수준 작업이 종종 실패합니다. 예를 들어 "ubiquitous"라는 문자열을 주고 "첫 번째부터 시작해서 세 번째 문자만 출력해"라고 요청합니다. U로 시작하고 세 번째마다 가야 합니다.

1, 2, 3, Q가 다음이어야 합니다. 등등. 이것은 맞지 않아 보이고, 제 가설은 여기서 암산이 약간 실패하고 있다는 것입니다. 하지만 더 중요한 문제는 Tiktokenizer에 가서 ubiquitous를 보면 세 개의 토큰이라는 것입니다. 우리는 ubiquitous를 보고 개별 글자에 쉽게 접근할 수 있습니다. 그것을 보기 때문입니다. 시각적 필드의 작업 메모리에 있으면 매우 쉽게 세 번째 글자마다 인덱싱할 수 있고 그 작업을 할 수 있습니다. 하지만 모델은 개별 글자에 접근할 수 없습니다. 이것을 이 세 개의 토큰으로 봅니다. 이 모델들은 인터넷에서 처음부터 학습되고 기본적으로 모델이 모든 다른 글자가 모든 다른 토큰에 몇 개 들어있는지 발견해야 합니다. 토큰을 사용하는 이유는 대부분 효율성 때문입니다.

하지만 많은 사람들이 토큰을 완전히 삭제하는 것에 관심이 있습니다. 문자 수준이나 바이트 수준 모델이 있어야 합니다. 다만 그것은 매우 긴 시퀀스를 만들고 사람들이 지금 그것을 어떻게 다룰지 모릅니다. 토큰 세계가 있는 한 어떤 종류의 철자 작업도 실제로 잘 작동하지 않을 것입니다. 토큰화 때문에 철자가 강점이 아니라는 것을 알기 때문에 다시 도구에 의존하도록 요청할 수 있습니다. "코드 사용"이라고 말하면 ubiquitous를 Python 인터프리터에 복사 붙여넣기하는 작업이 훨씬 쉽고 Python 인터프리터에 의존해 이 문자열의 문자를 조작하기 때문에 작동할 것으로 예상합니다. "코드 사용" ubiquitous 네, 세 번째 문자마다 인덱싱하고 실제 진실은 u2s uqs입니다. 맞아 보입니다.

다시 철자 관련 작업이 잘 작동하지 않는 예시입니다. 최근 매우 유명한 예시는 "strawberry에 r이 몇 개야?"입니다. 여러 번 바이럴이 되었고 기본적으로 모델이 이제 맞게 답합니다. strawberry에 r이 세 개 있다고 하지만, 오랫동안 모든 최첨단 모델이 strawberry에 r이 두 개밖에 없다고 주장했습니다. 이것은 많은 소동을 일으켰습니다. 모델이 너무 뛰어나서 수학 올림피아드 문제를 풀 수 있는데 strawberry에서 r을 세지 못하는 이유가 뭐냐고요. 그것에 대한 답은 다시, 천천히 쌓아왔지만, 첫째, 모델은 문자를 보지 않고 토큰을 봅니다. 둘째, 세기를 잘 못합니다. 여기서 문자를 보는 어려움과 세기의 어려움을 결합하고 있습니다.

그래서 모델이 이것에 어려움을 겪었습니다. 솔직히 지금쯤 OpenAI가 여기서 답을 하드코딩했을 수도 있고 무엇을 했는지 모르겠지만, 이 특정 쿼리는 이제 작동합니다. 모델은 철자를 잘 못하고 다른 작은 날카로운 경계들도 있습니다. 모두 다루고 싶지는 않습니다. 알아야 할 몇 가지 예시만 보여드리고 싶습니다. 이 모델들을 실제로 사용할 때요. 실제로 모델이 부족한 모든 방식에 대한 포괄적인 분석을 하고 싶지 않습니다.

---
