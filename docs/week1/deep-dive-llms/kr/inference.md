---
title: "6. Inference"
titleKr: "6. 추론"
chapter: 6
timestamp: "26:01"
sourceUrl: "https://www.youtube.com/watch?v=7xTGNNLPyMI&t=1561s"
translatedAt: "2026-01-10"
---

# 6. 추론

[영상 바로가기 (26:01)](https://www.youtube.com/watch?v=7xTGNNLPyMI&t=1561s)

## 요약

훈련된 모델로 새로운 텍스트를 생성하는 추론(inference) 과정을 설명합니다. 시작 토큰(접두사)을 입력하면 모델이 확률 분포를 출력하고, 이 분포에서 다음 토큰을 샘플링합니다. 샘플링된 토큰을 다시 입력에 추가하고 이 과정을 반복하여 텍스트를 생성합니다. 이 과정은 확률적이므로 같은 입력에도 매번 다른 결과가 나올 수 있으며, 훈련 데이터의 "리믹스"를 생성합니다.

**핵심 개념:**
- **추론(Inference)**: 훈련된 모델로 새로운 데이터를 생성하는 과정
- **접두사(Prefix)**: 텍스트 생성을 시작하기 위한 초기 토큰 시퀀스
- **샘플링**: 확률 분포에서 다음 토큰을 무작위로 선택하는 과정
- **확률적 생성**: 높은 확률의 토큰이 더 자주 선택되지만 결과는 매번 다름
- **자기회귀(Autoregressive)**: 생성된 토큰을 다시 입력에 추가하여 다음 토큰을 예측
- **훈련 데이터의 리믹스**: 원본과 동일하지 않지만 통계적으로 유사한 패턴의 새 텍스트

---

## 전체 번역

**요약**: 학습된 모델로 텍스트를 생성하는 추론(inference) 과정을 설명합니다. 모델은 확률 분포에서 다음 토큰을 샘플링하고, 이를 반복하여 텍스트를 생성합니다. 추론은 학습보다 훨씬 빠르며, 단일 GPU로도 가능합니다.

[26:30] 기본적으로 접두사, 시작하고 싶은 것인 몇 개의 토큰으로 시작합니다. 토큰 91로 시작하고 싶다고 합시다. 네트워크에 입력하면 네트워크가 확률을 준다는 것을 기억하세요. 이 확률 벡터를 줍니다. 이제 기본적으로 편향된 동전을 던질 수 있습니다. 이 확률 분포를 기반으로 토큰을 샘플링할 수 있습니다. 모델에 의해 높은 확률이 주어진 토큰들은

[27:00] 이 편향된 동전을 던질 때 샘플링될 가능성이 더 높다고 생각할 수 있습니다. 분포에서 샘플링해서 단일 고유 토큰을 얻습니다. 예를 들어 토큰 860이 다음에 옵니다. 860은 이 경우 모델에서 생성할 때 다음에 올 수 있습니다. 860은 상대적으로 가능성이 높은 토큰이고, 이 경우 유일하게 가능한 토큰이 아닐 수 있고 다른 많은 토큰이 샘플링될 수 있었지만, 860이 상대적으로 가능성이 높은 토큰이라는 것을 볼 수 있습니다. 실제로 우리 훈련 예시에서

[27:30] 860이 91 다음에 옵니다. 이제 과정을 계속한다고 합시다. 91 다음에 860이 있고, 추가하고 세 번째 토큰이 무엇인지 다시 물어봅니다. 샘플링하고 여기와 정확히 같은 287이라고 합시다. 다시 해봅시다. 세 개의 시퀀스를 가지고 네 번째 토큰이 뭘지 물어보고 그것에서 샘플링해서 이것을 얻습니다. 이제 한 번 더 해봅시다.

[28:00] 네 개를 취하고 샘플링해서 이것을 얻습니다. 이 13659는 실제로 이전에 있던 3962가 아닙니다. 이 토큰은 "article" 토큰입니다. 그래서 "viewing a single article"이고, 이 경우 훈련 데이터에서 본 시퀀스를 정확히 재현하지 않았습니다. 이 시스템들이 확률적이라는 것을 기억하세요. 샘플링하고 동전을 던지고, 때때로 운이 좋아서

[28:30] 훈련 세트의 텍스트의 작은 청크를 재현하지만, 때때로 훈련 데이터의 어떤 문서에도 그대로 포함되지 않은 토큰을 얻습니다. 그래서 훈련에서 본 데이터의 일종의 리믹스를 얻게 됩니다. 매 단계마다 뒤집어서 약간 다른 토큰을 얻을 수 있고, 그 토큰이 들어오면 다음 것을 샘플링하고 등등... 매우 빠르게 훈련 문서에 있는 토큰 스트림과는

[29:00] 매우 다른 토큰 스트림을 생성하기 시작합니다. 통계적으로 비슷한 속성을 가지겠지만 훈련 데이터와 동일하지 않습니다. 훈련 데이터에서 영감을 받은 것입니다. 이 경우 약간 다른 시퀀스를 얻었고, 왜 "article"을 얻었을까요? "article"이 "bar viewing single" 등의 맥락에서 상대적으로 가능성이 높은 토큰이라고 상상할 수 있고, "article"이라는 단어가 훈련 문서 어딘가에서 이 컨텍스트 윈도우를 어느 정도 따랐고,

[29:30] 우리가 이 단계에서 그것을 샘플링한 것입니다. 기본적으로 추론은 이 분포들에서 한 번에 하나씩 예측하고, 토큰을 계속 다시 입력하고 다음 것을 얻고, 항상 동전을 던지고 얼마나 운이 좋거나 나쁘냐에 따라 이 확률 분포에서 어떻게 샘플링하느냐에 따라 매우 다른 종류의 패턴을 얻을 수 있습니다. 이것이 추론입니다. 가장 일반적인 시나리오에서 기본적으로 인터넷을 다운로드하고 토큰화하는 것은

[30:00] 한 번 하는 전처리 단계이고, 토큰 시퀀스를 갖게 되면 네트워크를 훈련하기 시작할 수 있습니다. 실제 경우에는 다양한 종류의 설정, 다양한 종류의 배열, 다양한 종류의 크기의 많은 다른 네트워크를 훈련하려고 할 것이므로 많은 신경망 훈련을 하게 됩니다. 신경망을 훈련하고 만족스러운 특정 파라미터 세트를 갖게 되면 모델을 가져와서 추론을 하고 실제로

[30:30] 모델에서 데이터를 생성할 수 있습니다. ChatGPT에서 모델과 대화할 때, 그 모델은 아마 수개월 전에 OpenAI에 의해 훈련되었고 잘 작동하는 특정 가중치 세트를 가지고 있습니다. 모델과 대화할 때 그것은 모두 추론일 뿐입니다. 더 이상 훈련이 없고, 파라미터는 고정되어 있고, 모델과 대화하고 있는 것입니다. 토큰 몇 개를 주면 토큰 시퀀스를 완성하고, ChatGPT에서 실제로 모델을 사용할 때 생성되는 것을 보는 것입니다.

[31:00] 그 모델은 추론만 합니다. 이제 구체적인 훈련과 추론의 예시를 보고 이 모델들이 훈련될 때 실제로 어떻게 보이는지 감을 드리겠습니다. 제가 다루고 싶고 특히 좋아하는 예시는 OpenAI의 GPT-2입니다. GPT는 Generatively Pre-trained Transformer(생성적 사전훈련 트랜스포머)를 의미하고, 이것은 OpenAI의 GPT 시리즈의 두 번째 버전입니다. 오늘날 ChatGPT와 대화할 때 그 마법의 기반이 되는 모델은

---
