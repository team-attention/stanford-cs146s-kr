---
title: "생성적 지식 프롬프팅 (Generated Knowledge Prompting)"
source_url: "https://www.promptingguide.ai/techniques/knowledge"
source_type: web
author: "DAIR.AI"
fetch_date: "2026-01-08"
translatedAt: "2026-01-08"
status: "final"
---

# 생성적 지식 프롬프팅 (Generated Knowledge Prompting)

## 핵심 요약

- **개념**: 예측 전에 모델이 먼저 관련 지식을 생성하도록 유도하는 기법
- **목적**: 세계 지식이 필요한 작업에서 LLM의 정확도 향상
- **방법**: 1단계(지식 생성) → 2단계(통합 및 예측)의 2단계 접근
- **효과**: 상식 추론 작업에서 기존 방식보다 더 정확한 응답 도출

---

## 개요

생성적 지식 프롬프팅은 LLM에게 "예측하기 전에 먼저 지식을 생성하라"고 지시하여 성능을 높이는 기법입니다. 기존에 학습된 파라미터에만 의존하지 않고, 모델이 먼저 관련 정보를 생성한 뒤 더 정확한 출력을 도출합니다.

## 문제 상황

일반적인 LLM 응답은 세계 지식이 필요한 작업에서 자주 실패합니다. 예를 들어, "골프에서는 다른 사람보다 높은 점수를 얻으려고 합니다. 예, 아니오?"라는 질문에 모델은 맥락을 제대로 이해하지 못한 채 "예"라고 잘못 답했습니다.

## 해결책: 다단계 접근

### 1단계: 지식 생성

이 기법은 먼저 주제와 관련된 사실을 생성하도록 모델을 유도합니다. 골프 예시에서 모델은 두 가지 지식을 생성했습니다:

- 골프를 "가장 적은 타수로 전체 홀을 완주하는" 게임이며 "총 타수로 승자를 결정한다"고 설명하는 지식
- 골프를 "가장 낮은 점수로 코스를 완주하는" 스포츠로 설명하는 지식

### 2단계: 통합 및 예측

생성된 지식을 재구성한 프롬프트(주로 QA 형식)에 통합하여 모델이 정확한 답변을 도출하도록 안내합니다.

## 주요 결과

지식을 통합하자 모델은 신뢰도에 따라 가중치를 부여한 답변을 제공했습니다:

- **답변 1** (높은 신뢰도): 골프는 높은 점수가 아닌 *낮은* 점수를 목표로 한다고 정확히 파악
- **답변 2** (낮은 신뢰도): 생성된 지식을 잘못 해석

## 연구 배경

이 기법은 Liu et al. (2022)이 제안했으며, 프롬프팅 파이프라인 내에 명시적인 지식 생성 단계를 추가하여 상식 추론 작업의 한계를 극복합니다.
