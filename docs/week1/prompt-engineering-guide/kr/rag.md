---
title: "검색 증강 생성(Retrieval Augmented Generation)"
source_url: "https://www.promptingguide.ai/techniques/rag"
source_type: web
author: "DAIR.AI"
fetch_date: "2026-01-08"
translatedAt: "2026-01-08"
status: "final"
---

# 검색 증강 생성(RAG)

## 핵심 요약

- **RAG**는 정보 검색과 텍스트 생성을 결합하여 LLM의 사실적 정확성을 높이는 기법이다
- 외부 지식을 활용해 환각(hallucination) 문제를 완화하고, 최신 정보를 반영할 수 있다
- 문서 저장소, 검색기(Retriever), 생성기(Generator) 세 구성요소로 이루어진다
- 질의응답, 사실 검증, 콘텐츠 생성, 고객 지원 등 다양한 분야에 적용한다

---

범용 언어 모델은 감정 분석이나 개체명 인식 같은 일반적인 태스크에 맞춰 파인튜닝할 수 있다. 이런 태스크는 대체로 추가적인 배경 지식이 필요하지 않다.

하지만 더 복잡하고 지식 집약적인 태스크라면, 외부 지식 소스에 접근하는 언어 모델 기반 시스템을 구축할 수 있다. 이 방식은 사실적 일관성을 높이고, 생성된 응답의 신뢰성을 향상시키며, 환각(hallucination) 문제를 완화한다.

Meta AI 연구진은 이러한 지식 집약적 태스크를 해결하기 위해 **검색 증강 생성(Retrieval Augmented Generation, RAG)**을 제안했다. RAG는 정보 검색 컴포넌트와 텍스트 생성 모델을 결합한다. RAG는 파인튜닝할 수 있으며, 전체 모델을 재학습하지 않고도 내부 지식을 효율적으로 수정할 수 있다.

## RAG의 작동 원리

RAG는 입력을 받아 소스(예: Wikipedia)에서 관련성 있는 문서들을 검색한다. 검색된 문서는 원래 입력 프롬프트와 함께 컨텍스트로 결합되어 텍스트 생성기에 전달되고, 최종 출력을 생성한다. 이 방식 덕분에 RAG는 사실이 시간에 따라 변하는 상황에도 유연하게 대응할 수 있다. LLM의 파라메트릭 지식은 정적이므로 이 점이 매우 유용하다. RAG를 사용하면 언어 모델이 재학습 없이 최신 정보에 접근하여 검색 기반 생성을 통해 신뢰할 수 있는 출력을 만들 수 있다.

Lewis 등(2021)은 RAG를 위한 범용 파인튜닝 방법론을 제안했다. 사전 학습된 seq2seq 모델을 파라메트릭 메모리로 사용하고, Wikipedia의 밀집 벡터 인덱스를 비파라메트릭 메모리로 사용한다(신경망 기반 사전 학습 검색기로 접근). 아래는 이 접근법의 작동 방식 개요다:

RAG 모델은 문서를 검색하고, 이를 조건으로 삼아 텍스트를 생성한다. 검색기와 생성기 컴포넌트를 end-to-end로 함께 학습한다.

## RAG의 성능

RAG는 Natural Questions, WebQuestions, CuratedTrec 등 여러 벤치마크에서 강력한 성능을 보여준다. MS-MARCO와 Jeopardy 질문으로 테스트했을 때, RAG는 더 사실적이고, 구체적이며, 다양한 응답을 생성한다. RAG는 FEVER 사실 검증에서도 결과를 개선한다.

이는 지식 집약적 태스크에서 언어 모델의 출력을 향상시키는 유효한 방법으로서 RAG의 잠재력을 보여준다.

최근에는 이러한 검색 기반 접근법이 더욱 인기를 얻어 ChatGPT 같은 LLM과 결합하여 기능과 사실적 일관성을 개선하고 있다.

## RAG 활용 사례

RAG는 다양한 지식 집약적 시나리오에 적용할 수 있다:

- **질의응답**: 관련 문서를 검색하여 정확하고 최신의 답변 제공
- **사실 검증**: 신뢰할 수 있는 지식 소스와 주장을 대조 검증
- **콘텐츠 생성**: 권위 있는 출처를 참조하여 사실에 기반한 콘텐츠 작성
- **고객 지원**: 제품 문서와 FAQ에 접근하여 정확한 응답 제공

## 실제 구현

RAG 시스템을 구현할 때 다음 구성요소를 고려해야 한다:

1. **문서 저장소**: 검색할 수 있는 문서 컬렉션 (예: 벡터 데이터베이스)
2. **검색기(Retriever)**: 쿼리 기반으로 관련 문서를 찾는 모델
3. **생성기(Generator)**: 검색된 컨텍스트를 활용하여 최종 응답을 생성하는 언어 모델

이 가이드에는 오픈소스 LLM을 사용하여 머신러닝 논문 제목을 생성하는 최소한의 RAG 시스템 구축 방법을 보여주는 노트북 튜토리얼이 포함되어 있다.

## 참고 문헌

- Lewis, P., et al. (2020). Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks. NeurIPS 2020.
- Gao, Y., et al. (2023). Retrieval-Augmented Generation for Large Language Models: A Survey.
