---
title: "Zero-shot 프롬프팅"
originalTitle: "Zero-shot Prompting"
source_url: "https://www.promptingguide.ai/techniques/zeroshot"
author: "DAIR.AI"
translatedAt: "2026-01-08"
status: "final"
---

# Zero-shot 프롬프팅

## 정의

Zero-shot 프롬프팅은 프롬프트에 예시나 시연을 포함하지 않는 방식입니다. GPT-3.5 Turbo, GPT-4, Claude 3 같은 최신 LLM은 대규모 학습을 통해 이 방식으로도 작업을 수행할 수 있습니다.

## 작동 원리

모델이 시연 없이 직접 작업 지시를 받습니다. 예를 들어, 감성 분류 프롬프트는 텍스트를 중립적, 부정적, 긍정적으로 분류하라고 요청합니다. 모델은 레이블이 붙은 예시 없이도 개념을 이해합니다.

## 예시

**프롬프트:**
```
텍스트를 중립적, 부정적, 긍정적으로 분류하세요.
텍스트: 이번 휴가는 괜찮은 것 같아.
감성:
```

**결과:** 중립적

## 핵심 기술

다음 두 가지 기술이 zero-shot 성능을 크게 향상시켰습니다:

1. **Instruction Tuning** - 지시문 기반 데이터셋으로 파인튜닝하면 zero-shot 성능이 향상됩니다
2. **RLHF (Reinforcement Learning from Human Feedback)** - 인간의 선호도에 맞게 모델을 정렬하는 기법으로, ChatGPT 같은 모델의 핵심 기술입니다

## 대안 사용 시점

Zero-shot으로 원하는 결과를 얻지 못하면 few-shot 프롬프팅으로 전환하는 것을 권장합니다. Few-shot은 모델 응답을 유도하는 예시를 포함합니다.

---

## 핵심 요약

- Zero-shot은 예시 없이 직접 지시만으로 작업을 수행하는 프롬프팅 기법
- 최신 LLM은 광범위한 사전 학습으로 zero-shot 수행이 가능
- Instruction Tuning과 RLHF가 zero-shot 성능 향상의 핵심
- 성능이 부족하면 few-shot 프롬프팅을 고려

<!--
## Refiner 변경 사항 (3차 - 최종)

### 1차 정제 (기본 교정)
- "상호작용할 때 사용하는 프롬프트에" → "프롬프트에" (간결화)
- "광범위한 학습 덕분에 이런 방식으로도" → "대규모 학습을 통해 이 방식으로도" (간결화)
- "직접적인 작업 지시만 받습니다" → "직접 작업 지시를 받습니다" (자연스러움)
- "Zero-shot 성능을 향상시킨 두 가지 기술이 있습니다" → "두 가지 기술이 zero-shot 성능을 향상시켰습니다" (능동태)

### 2차 정제 (validator 피드백)
- "레이블된 예시" → "레이블이 붙은 예시" (자연스러움)
- "인간 피드백으로 모델을 정렬" → "인간의 선호도에 맞게 모델을 정렬" (원문 정확성)
- "전환하세요" → "전환하는 것을 권장합니다" (원문 뉘앙스 유지)

### 3차 정제 (QA 피드백 + 최종화)
- "두 가지 기술이" → "다음 두 가지 기술이 ... 크게" (강조 뉘앙스 추가)
- RLHF 설명 문장 구조 개선
- "대규모 사전 학습" → "광범위한 사전 학습" (원문 'extensive' 일관성)
- frontmatter status를 "final"로 설정
-->
