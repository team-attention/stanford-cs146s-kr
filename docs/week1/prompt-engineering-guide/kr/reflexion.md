---
title: "Reflexion"
originalTitle: "Reflexion"
author: "DAIR.AI"
sourceUrl: "https://www.promptingguide.ai/techniques/reflexion"
translatedAt: "2026-01-08"
status: "final"
---

# Reflexion

## 개요

Reflexion은 언어적 피드백을 통해 언어 기반 에이전트를 강화하도록 설계된 프레임워크입니다. 연구에 따르면 "에이전트의 메모리 인코딩과 LLM 매개변수 선택을 조합해 정책을 매개변수화"합니다.

핵심 메커니즘은 환경 피드백을 언어적 자기 성찰로 변환한 뒤, 이후 에이전트 반복 시 컨텍스트로 활용합니다. 이 방식으로 에이전트는 실수에서 배우고 복잡한 작업 성능을 높입니다.

## 프레임워크 구성요소

Reflexion 시스템은 세 가지 모델로 구성됩니다:

**액터(Actor)**: 관찰을 바탕으로 텍스트와 행동을 생성하며, Chain-of-Thought와 ReAct 방법론을 사용합니다. 의사 결정 향상을 위한 추가 컨텍스트를 제공하는 메모리 구성요소를 포함합니다.

**평가자(Evaluator)**: 궤적(trajectory)을 분석하고 보상 점수를 생성해 액터의 출력을 평가합니다. 작업별 보상 함수는 LLM과 규칙 기반 휴리스틱을 함께 활용합니다.

**자기 성찰(Self-Reflection)**: 언어적 강화 신호를 생성하는 LLM 기반 구성요소입니다. 보상 신호, 현재 궤적, 지속 메모리를 활용해 개선을 위한 구체적인 피드백을 제공합니다.

## 프로세스 흐름

Reflexion의 프로세스는 다음 단계를 따릅니다: 작업 정의 → 궤적 생성 → 평가 → 성찰 → 다음 궤적 생성.

## 성능 결과

연구 결과 여러 영역에서 상당한 개선을 확인했습니다:

- **의사 결정**: ReAct + Reflexion이 AlfWorld 작업 134개 중 130개 완료
- **추론**: HotPotQA에서 기존 접근법 대비 우수한 성능
- **프로그래밍**: HumanEval, MBPP, Leetcode Hard 벤치마크에서 최고 수준 달성

## 이상적인 사용 사례

Reflexion은 다음 상황에서 가장 효과적입니다:

- 에이전트가 시행착오를 통해 학습해야 할 때
- 전통적인 강화 학습이 현실적으로 어려울 때
- 미묘하고 해석 가능한 피드백이 필수일 때
- 명시적인 에피소드 메모리가 작업에 유용할 때

## 한계점

- 정확한 자기 평가 능력이 필요함
- 슬라이딩 윈도우 아키텍처의 메모리 제약
- 비결정적 함수가 포함된 코드 생성 시 어려움

---

## 핵심 요약

- Reflexion은 언어적 자기 성찰을 통해 에이전트를 강화하는 프레임워크
- 액터, 평가자, 자기 성찰 세 가지 구성요소로 이루어짐
- 의사 결정, 추론, 프로그래밍 작업에서 우수한 성능
- 시행착오 학습과 해석 가능한 피드백이 필요한 상황에 적합
