---
title: "현대 코드 리뷰에서의 AI 지원 코딩 관행 평가"
originalTitle: "AI-Assisted Assessment of Coding Practices in Modern Code Review"
author: "Manushree Vijayvergiya et al. (Google)"
sourceUrl: "https://arxiv.org/pdf/2405.13565"
translatedAt: "2026-01-13"
status: "final"
contentType: "pdf"
qaScore:
  consistency: 9
  readability: 8
  accuracy: 9
  overall: 9
---

# 현대 코드 리뷰에서의 AI 지원 코딩 관행 평가

[원본 링크](https://arxiv.org/pdf/2405.13565)

## 초록

현대 코드 리뷰는 코드 작성자가 만든 증분 코드 변경사항을 버전 관리 시스템에 커밋하기 전에 한 명 이상의 동료가 검토하는 프로세스입니다. 현대 코드 리뷰의 중요한 요소 중 하나는 코드 기여물이 모범 사례를 준수하는지 확인하는 것입니다. 이러한 모범 사례 중 일부는 자동 검증이 가능하지만, 나머지는 일반적으로 사람 검토자가 담당합니다. 이 논문은 코딩 모범 사례를 자동으로 학습하고 적용하는 대규모 언어 모델(LLM) 기반 시스템인 AutoCommenter의 개발, 배포, 평가에 대해 보고합니다. 저자들은 4개의 프로그래밍 언어(C++, Java, Python, Go)에 대해 AutoCommenter를 구현했으며, 대규모 산업 환경에서 성능과 채택률을 평가했습니다. 평가 결과, 코딩 모범 사례를 학습하고 적용하는 엔드투엔드 시스템 구축이 가능하며 개발자 워크플로우에 긍정적인 영향을 미친다는 것을 보여줍니다. 또한 이 논문은 수만 명의 개발자에게 이러한 시스템을 배포하는 것과 관련된 도전 과제와 그에 따른 교훈을 보고합니다.

**키워드**: 인공지능, 코드 리뷰, 코딩 모범 사례

## 1. 서론

현대 코드 리뷰(전체적 코드 리뷰와 비교하여)는 오픈소스 및 산업 환경에서 수년간 유기적으로 발전했습니다. 코딩 모범 사례를 포함하는 일련의 공통 동료 리뷰 기준이 등장했습니다. 많은 회사, 프로젝트, 심지어 프로그래밍 언어에서 이를 "스타일 가이드" 형태로 공식 정의하며, 일반적으로 다음 측면을 다룹니다:

- **포매팅**: 줄 제한, 공백 및 들여쓰기 사용, 괄호 및 중괄호 배치 등
- **네이밍**: 대소문자 구분, 간결함, 설명적 명명 등
- **문서화**: 파일 수준, 함수 수준 및 기타 주석의 예상 위치와 내용
- **언어 기능**: 다양한 (코드) 컨텍스트에서 특정 언어 기능의 사용
- **코드 관용구**: 코드 명확성, 모듈성 및 유지보수성을 개선하기 위한 코드 관용구 사용

개발자들은 일반적으로 현대 코드 리뷰 프로세스에 대해 높은 만족도를 느낍니다. 주요 이점 중 하나는 코드베이스, 특정 언어 기능 또는 일반적인 코드 관용구에 익숙하지 않은 코드 작성자를 위한 학습 경험입니다. 리뷰 과정에서 전문 개발자가 코드 작성자에게 모범 사례를 교육합니다.

린터와 같은 정적 분석 도구는 코드가 일부 모범 사례(예: 포매팅 규칙)를 준수하는지 자동으로 검증할 수 있으며, 일부 도구는 위반 사항을 자동으로 수정할 수도 있습니다. 그러나 미묘한 가이드라인이나 예외가 있는 가이드라인은 전체적으로 자동 검증하기 어렵고(예: 명명 규칙 및 레거시 코드에서의 정당한 예외), 일부 가이드라인은 정확한 규칙으로 포착할 수 없어(예: 코드 주석의 명확성과 구체성) 인간의 판단과 개발자들의 축적된 지식이 필요합니다.

코드 리뷰 프로세스의 가장 큰 비용은 필요한 시간이며, 특히 전문 개발자의 시간입니다. 상당한 자동화가 이루어지고 프로세스를 최대한 가볍게 유지하더라도, 개발자는 이 작업에 쉽게 하루에 몇 시간을 할애할 수 있습니다.

기계 학습의 최근 발전, 특히 대규모 언어 모델(LLM)의 기능은 LLM이 코드 리뷰 자동화에 적합하다는 것을 시사합니다. 그러나 대규모로 엔드투엔드 시스템을 배포하는 것과 관련된 소프트웨어 엔지니어링 과제는 아직 충분히 탐구되지 않은 영역입니다.

### 기여

- LLM 기반 코드 리뷰 지원 시스템의 일반 아키텍처
- 수만 명의 개발자에게 도구 보정 및 배포에 대한 설명
- 시스템 평가
- 교훈 요약 및 논의

## 2. 배경

### 2.1 코드 리뷰 프로세스

Google의 코드 리뷰 프로세스는 체계적으로 확립되어 있으며, 변경 단위로 진행되고 도구의 지원을 받습니다. 코드베이스에 대한 각 변경은 최소 한 명의 다른 개발자가 검토해야 합니다. 매일 수만 건의 코드베이스 변경이 리뷰 프로세스를 거치며, 코드 작성자와 검토자로서 수만 명의 개발자가 프로세스에 참여합니다.

작성자와 검토자는 코드 리뷰 시스템을 통해 코멘트를 교환하고, 리뷰는 변경의 영향을 받는 파일의 스냅샷을 통해 진행됩니다. 각 검토자 코멘트는 특정 파일 스냅샷의 특정 줄과 열 범위에 첨부됩니다.

코드 리뷰 프로세스에서 가장 비용이 많이 드는 부분은 코드 작성자와 검토자가 변경을 관리하는 데 소비하는 시간입니다(초기 코딩부터 검토자 코멘트 처리, 모든 자동화된 분석 통과 확인, 최종적으로 변경을 코드베이스에 병합하는 것까지). 프로세스가 리뷰 전에 코드를 분석하는 자동화된 시스템으로 최적화되어 있지만(특히 인간 개입 없이 자동 코드 포매팅), 코드 리뷰는 여전히 연간 수천 개발자-년의 비용이 듭니다.

### 2.2 모범 사례

**모범 사례(best practice)**는 더 우수하다고 여겨지는 프로그래밍 언어의 특정 사용법이며, **모범 사례 문서**는 적용 방법과 이점을 설명합니다. **모범 사례 URL**은 모범 사례 문서 또는 그 특정 섹션을 참조하고, **모범 사례 위반**은 모범 사례를 준수하지 않지만 준수하도록 변경할 수 있는 특정 코드 조각을 의미합니다.

Google의 중앙 코드 저장소에는 여러 언어의 코드가 포함되어 있으며, C++, Java, Python, Go가 각각 1억 줄 이상입니다. 15개의 다른 언어에 대해 모든 개발자가 쉽게 이용할 수 있는 공식 스타일 가이드가 있습니다.

모범 사례가 일관되게 준수되도록 하는 "가독성(readability)"이라는 공식 메커니즘이 10년 전에 도입되었습니다. "가독성 멘토"라고 불리는 특정 언어의 전문 스타일 전문가가 해당 언어에 미숙한 개발자의 숙련도 향상을 돕습니다.

## 3. 접근 방식

### 3.1 모델 및 작업 정의

모범 사례 분석 자동화에는 소스 코드를 표현하고, 위반 위치를 정확히 찾아내고, 위반된 모범 사례를 식별할 수 있는 모델이 필요합니다. 저자들은 T5를 기반으로 한 전통적인 트랜스포머(Transformer) 접근 방식을 사용하여 텍스트-투-텍스트 변환(text-to-text transformation) 방식을 채택하며, T5X를 사용합니다.

모범 사례 분석을 위해 모델의 **입력**은 작업 프롬프트와 소스 코드이고, **타겟**은 모범 사례 위반에 대한 소스 코드 위치와 URL입니다. 작업 프롬프트는 프로그래밍 언어의 적절한 주석 스타일을 사용하여 고정 텍스트 코드 주석으로 형식화됩니다.

**예시 입력 (Go 언어):**
```go
// [*] Task: Check language best practices.
// Package addition provides Add
package addition

// Return a sum
func Add(value1, value2 int) int {
    return value1 + value2
}
```

**타겟:**
```
INSERT 153 COMMENT https://go.dev/doc/comment#func
```

타겟은 위치(바이트 오프셋 153은 Add 함수의 시작에 해당)와 함수 주석이 위반하는 Go 언어 스타일 가이드의 정확한 부분을 가리키는 go.dev URL을 제공합니다.

### 3.2 모델 훈련

모델 훈련 파이프라인은 세 부분으로 구성됩니다:

1. **대규모 전처리 (주기적)**: 모범 사례 문서를 가리키는 URL이 포함된 인간이 작성한 관련 코드 주석을 식별합니다. 각 주석에 대해 해당 소스 코드와 관련 메타데이터를 수집합니다.

2. **데이터셋 큐레이션 (필요시)**: 각 관련 코드 주석을 표준 TensorFlow Example 데이터 구조로 변환합니다.

3. **훈련 및 파인튜닝 (필요시)**: TPU 클러스터에서 T5X 프레임워크를 사용하여 1000 스텝마다 모델 체크포인트를 저장합니다.

### 3.3 모델 선택

과거 데이터에 대한 두 가지 내재적 평가가 모델 체크포인트, 신뢰도 임계값 및 디코딩 전략 선택에 정보를 제공합니다:

1. 검증 및 테스트 데이터셋에 대한 평가 (파일별 정밀도와 재현율 추정치 제공)
2. 전체 과거 코드 리뷰에 대한 평가 (코드 리뷰당 총 코멘트 수 추정치 제공)

### 3.4 추론 인프라

AutoCommenter의 핵심은 중앙 모범 사례 분석 서비스입니다. 이 서비스는 분석을 위해 하나 이상의 소스 파일을 입력으로 받습니다. 각 파일에 대해 모델 입력을 구성하고, 표준 TensorFlow Example 데이터 구조로 인코딩한 다음 모델에 쿼리합니다.

### 3.5 IDE 및 코드 리뷰 통합

개발자는 두 가지 방법으로 AutoCommenter의 분석 서비스와 상호작용합니다:
- IDE 플러그인을 통해 직접
- 코드 리뷰 시스템을 통해 간접적으로

AutoCommenter의 코멘트는 IDE에서 관련 코드 스니펫에 걸쳐 파란색 물결 밑줄로 표시되는 진단으로 나타납니다. 코드 리뷰 시스템에서 AutoCommenter는 각 업데이트 후 실행되어 위반이 감지되면 자동으로 코멘트를 게시합니다.

## 4. 배포

AutoCommenter는 2022년 7월부터 2023년 10월까지의 기간 동안 Google의 모든 개발자에게 배포되었습니다:

- 2022년 7월까지—팀푸딩(내부 테스트): 논문 저자들
- 2022년 7월—얼리 어답터: 약 3천 명의 자원자
- 2023년 7월—A/B 실험: 전체 개발자의 약 절반
- 2023년 10월 이후—일반 사용 가능: 모든 개발자

### 4.1 임계값 및 디코딩 전략 선택

**임계값**: 초기 배포는 t = 0.98의 높은 신뢰도 임계값으로 시작했습니다. 검증 데이터셋에 대한 내재적 평가를 기반으로 URL별 임계값이 구현되었습니다.

**디코딩**: 빔 서치(Beam Search, n = 4개의 잠재적 응답 생성)는 게시 빈도를 3.9%로 3배 증가시켰고, 상당히 높은 URL 다양성을 산출했습니다: 가장 자주 게시되는 상위 10개 URL이 전체 코멘트의 41%를 차지했으며, 이는 그리디 서치(Greedy Search)의 80%와 비교됩니다.

### 4.2 오래된 모범 사례 억제

언어가 발전하거나 새로운 라이브러리가 도입되면 모범 사례도 발전합니다. 특정 모범 사례 예측의 억제는 조건부 필터링(소스 코드에서 정규 표현식 매칭)을 사용하여 구현되었습니다:
1. 동적으로 배포하고 즉시 적용할 수 있음
2. 예측의 세분화된 필터링 허용

### 4.3 선택된 코멘트의 독립적 평가

2023년 4월에 독립적인 인간 평가 연구에서 약 370개의 게시된 코멘트를 분석했습니다. 평가자 평가에서 유용한 비율은 60%로, 개발자 피드백의 54%보다 약간 높았습니다.

**유용하지 않은 코멘트의 패턴:**
- 여러 주제 또는 복잡한 주제
- 고품질 요약의 중요성
- 주관적이고 잠재적으로 논쟁적인 주제
- 일부 가이드라인에 대한 체계적인 모델 오류
- 정확하지만 가치가 낮은 코멘트

### 4.4 A/B 실험

2023년 7월에 AutoCommenter가 A/B 실험에서 전체 개발자의 약 절반에게 배포되었습니다. 결과는 다음을 보여주었습니다:
- 통계적으로 유의미한 변화 없음: 코드 리뷰의 총 기간, 코드 리뷰에 적극적으로 소요된 시간, 코멘트-응답 반복 횟수
- 코딩 속도의 약간의 개선

## 5. 평가

### 5.1 코멘트 해결

6000개의 스냅샷 쌍 분석 결과, 50%의 경우에서 원래 게시된 줄에서 제출된 스냅샷에 코멘트가 없었습니다. 수동 검사 결과, 이러한 경우의 80%에서 작성자가 수행한 변경이 문제를 직접 해결한 것으로 나타났습니다. 따라서 추정 코멘트 해결률은 약 40%입니다.

### 5.2 AutoCommenter vs. 인간 코멘트

AutoCommenter는 330개의 고유 URL에 대해 코멘트를 생성했습니다. AutoCommenter가 사용하는 URL 집합은 모범 사례 URL이 포함된 과거 인간 코멘트의 68%를 커버합니다. 상위 85개 URL이 AutoCommenter가 생성한 코멘트의 90%를 차지합니다.

### 5.3 AutoCommenter vs. 린터

가장 자주 예측되는 상위 50개 모범 사례 중 33/50(66%)의 위반 감지는 전통적인 정적 분석의 범위를 벗어납니다.

유형별 분포:
- **네이밍**: 대부분 린트 불가능
- **언어**: 혼합
- **포매팅**: 대부분 린트 가능
- **문서화**: 혼합
- **코드 관용구**: 대부분 린트 불가능

## 6. 교훈

- **전통적 분석 보완**: AutoCommenter의 LLM 지원 접근 방식은 인간 검토자가 자주 참조하는 모범 사례의 68%에 대해 코멘트를 생성합니다. 이 중 많은 것이 전통적인 정적 분석의 범위를 벗어납니다.

- **내재적 평가와 실제 성능**: 내재적 평가와 실제 성능은 상당히 다를 수 있습니다. 외재적 평가와 시스템 개선이 성공적인 배포에 필수적이었습니다.

- **사용자 수용 모니터링이 중요**: 몇 가지 부정적인 사용자 경험만으로도 자동화된 시스템에 대한 신뢰가 약화될 수 있습니다. 실제 피드백을 지속적으로 모니터링하고 분석하는 것이 중요했습니다. 간단한 억제 메커니즘만으로도 효과에 큰 희생 없이 사용자 수용률을 80% 이상으로 크게 개선할 수 있었습니다.

## 7. 관련 연구

Johnson은 거의 50년 전인 1977년에 C 린터를 도입했습니다. 최근 문헌 리뷰에서 자동화된 정적 분석에 관한 17,571개의 논문이 확인되었습니다. 코드 분석을 위한 기계 학습 사용은 비교적 새롭고 덜 이해된 분야입니다.

## 8. 결론

이 논문은 LLM 지원 코드 리뷰 지원 시스템인 AutoCommenter를 개발, 배포, 평가한 경험을 보고합니다. 평가 결과, 전통적인 도구를 훨씬 뛰어넘는 기능을 갖춘 엔드투엔드 시스템을 개발하면서도 높은 수준의 최종 사용자 수용을 달성하는 것이 가능함을 보여줍니다.

우선순위는 AutoCommenter가 매우 높은 정밀도를 갖도록 설계하여 긍정적인 개발자 경험을 보장하는 것이었습니다. 향후 연구에서는 특히 훈련 중 수만 개의 토큰 컨텍스트 윈도우와 추론 중 백만 개 이상의 토큰을 가진 현재 최신 모델을 활용하여 모델 및 시스템 아키텍처의 어떤 변경이 재현율을 개선할 수 있는지 탐구할 것입니다.

---

## 핵심 요약

- AutoCommenter는 Google에서 개발한 LLM 기반 코드 리뷰 지원 시스템으로, 코딩 모범 사례를 자동으로 학습하고 적용합니다
- 4개 언어(C++, Java, Python, Go) 지원, 수만 명의 개발자에게 성공적으로 배포됨
- T5 기반 트랜스포머 모델을 사용하여 소스 코드에서 모범 사례 위반을 감지하고 관련 문서 URL을 제공
- 전통적인 정적 분석 도구(린터)가 처리할 수 없는 66%의 모범 사례 위반을 감지할 수 있음
- 40%의 코멘트 해결률과 80% 이상의 사용자 수용률 달성
- 주요 교훈: 내재적 평가와 실제 성능의 차이, 사용자 수용 모니터링의 중요성, 간단한 억제 메커니즘의 효과
