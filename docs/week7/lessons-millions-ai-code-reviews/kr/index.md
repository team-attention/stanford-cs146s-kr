---
title: "수백만 AI 코드 리뷰에서 배운 교훈"
originalTitle: "Lessons from millions of AI code reviews"
author: "Tomas Reimers (Graphite)"
sourceUrl: "https://www.youtube.com/watch?v=TswQeKftnaw"
translatedAt: "2026-01-15"
status: "final"
contentType: "youtube"
duration: "10:21"
hasSummary: true
---

# 수백만 AI 코드 리뷰에서 배운 교훈

[원본 영상](https://www.youtube.com/watch?v=TswQeKftnaw)

<!-- SUMMARY_START -->

## TL;DR

Graphite의 Diamond는 AI 기반 코드 리뷰 시스템으로, AI가 생성한 코드의 버그를 AI로 검출하는 접근법을 제시합니다. 10,000개의 코멘트 분석을 통해 AI가 효과적으로 잡을 수 있는 버그 유형과 인간이 실제로 원하는 피드백의 교집합을 찾아 52%의 코멘트 수용률을 달성했습니다.

## 이 콘텐츠에서 배울 수 있는 것

- AI 코드 리뷰 시스템의 효과적인 피드백 유형과 한계 이해하기
- 2x2 매트릭스를 활용한 AI 코드 리뷰 품질 평가 프레임워크 학습하기
- AI 코드 리뷰의 성공 지표(다운보트 비율, 변경 수용률) 측정 방법 파악하기

---

## 핵심 포인트

- **AI 코드 리뷰의 잠재력**: AI 코드 생성량 증가에 따라 버그도 증가하며, AI 기반 코드 리뷰가 이를 해결할 수 있는 잠재력을 가짐
- **2x2 매트릭스 분류**: 효과적인 AI 리뷰를 위해 'LLM이 잡을 수 있는 것 vs 못 잡는 것'과 '인간이 원하는 것 vs 원치 않는 것'의 2x2 매트릭스로 분류
- **AI가 잘 잡는 버그**: 논리적 불일치, 실수로 커밋된 코드, 성능/보안 문제, 문서화 문제, 스타일 변경
- **AI의 한계**: 부족 지식(tribal knowledge)처럼 조직 고유의 맥락이 필요한 버그는 탐지 불가
- **필터링 필요**: 현학적 코멘트(주석 추가, 테스트 작성 요구 등)는 AI가 잡을 수 있어도 개발자가 원치 않는 피드백으로, 필터링 필요

<!-- SUMMARY_END -->

---

<!-- FULL_TRANSLATION_START -->

## 전체 번역

이 강연에 참석해 주신 모든 분들께 진심으로 감사드립니다. 이 컨퍼런스에 와주셔서 감사합니다. 저는 Tomas이고, Graphite의 공동 창업자 중 한 명입니다. 오늘은 AI 기반 곤충학에 대해 이야기하려고 합니다. 혹시 모르시는 분들을 위해 설명드리면, 곤충학(entomology)은 버그를 연구하는 학문입니다. 이것은 저희가 하는 일이고, 저희 마음에 매우 가까운 일이며, 저희 제품이 하는 일의 일부이기도 합니다.

Graphite에 대해 모르시는 분들을 위해 설명드리면, 저희는 Diamond라는 제품을 만듭니다. Diamond는 AI 기반 코드 리뷰어입니다. GitHub에 연결하면 버그를 찾아줍니다. 이 프로젝트는 약 1년 전에 시작되었습니다. 저희가 주목하기 시작한 것은 AI가 작성하는 코드의 양이 계속 늘어나고 있었는데, 버그의 양도 함께 늘어나고 있었다는 점입니다. 깊이 생각해 본 결과, 이것이 실제로 한 세트일 수 있다고 생각했습니다. 그래서 저희가 해야 할 일은 전반적으로 이러한 버그를 더 잘 해결할 방법을 찾는 것이었습니다. 기술적 발전을 고려할 때, 저희가 가장 먼저 주목한 것은 AI 자체였습니다. 그래서 질문을 던지기 시작했습니다. AI가 버그를 만들어내고 있지만, AI가 버그를 찾을 수도 있을까? AI가 우리를 도울 수 있을까?

저희는 Claude에게 "여기 PR이 있는데, 이 PR에서 버그를 찾을 수 있어?"라고 물어보기 시작했고, 초기 결과에 꽤 감명받았습니다. 실제로 이번 주 저희 코드베이스에서 가져온 예시가 있는데, 특정 상황에서 데이터베이스 ORM 클래스가 인스턴스화되지 않은 채로 반환되어 서버가 크래시되는 경우가 있었습니다. 이번 주 트위터에서 저희 봇이 발견한 또 다른 예시도 있는데, 특정 상황에서 테두리 반경 관련 수학 연산이 음수로 나누기를 발생시켜 프론트엔드가 크래시되는 경우였습니다.

그래서 질문에 답하자면, AI는 버그를 찾을 수 있습니다. 강연 끝. 농담입니다.

이걸 직접 시도해 보셨다면, 아마 정말 좌절스러운 경험을 하셨을 겁니다. 저희도 이런 것들을 봤습니다. "이 코드를 뭔가 다르게 업데이트해야 합니다", "CSS는 이렇게 작동하지 않아요"(실제로는 그렇게 작동하는데), 또는 제가 가장 좋아하는 것으로 "이 코드를 예전 방식으로 되돌려야 합니다, 왜냐하면 예전에 그렇게 했으니까요"라는 것들 말입니다. 이런 것들을 보면서 저희는 많은 신뢰를 잃었지만, 생각하기 시작했습니다. 정말 좋은 것들도 보이고 정말 나쁜 것들도 보이는데, 어쩌면 실제로 버그에는 여러 종류가 있는 것 아닐까? LLM이 찾을 수 있는 것에도 여러 종류가 있는 것 아닐까?

그래서 저희는 가장 기본적인 구분부터 시작했습니다. LLM이 잘 잡아내는 것들과 잘 잡아내지 못하는 것들이 있을 거라고요. 결국 LLM은 궁극적으로 여러분이 요청하는 것을 모방하려고 합니다. "이 PR에 어떤 종류의 코드 리뷰 코멘트가 달릴까요?"라고 물으면, LLM은 자신의 능력 범위 내에 있는 것과 능력 범위 밖에 있는 것 모두를 남깁니다. 그래서 저희는 이것들을 분류하기 시작했습니다.

하지만 분류를 해도 LLM이 이런 코멘트를 남기기 시작한다는 것을 발견했습니다. "이 클래스가 무엇을 하는지 설명하는 주석을 추가해야 합니다", "이 로직을 함수로 추출해야 합니다", "이 코드에 테스트가 있는지 확인해야 합니다". 기술적으로는 맞지만 개발자들에게는 정말 짜증스럽습니다. 이 프로젝트를 구축하면서 가장 통찰력 있는 순간 중 하나는 디자인 팀과 함께 앉아서 과거 버그들을 실제로 살펴볼 때였습니다. 저희 봇과 사람이 저희 코드베이스에 남긴 것들 모두요.

개발자들은 거의 같은 의견이었습니다. "응, LLM이 그걸 남겨도 괜찮아", "아니, LLM이 그걸 남기면 안 돼", "응, 괜찮아". 그런데 디자이너들은 실제로 당황했습니다. "근데 저것도 다른 코멘트랑 비슷해 보이는데요?"라고 했습니다. 제 생각에 개발자의 마음속에서 일어나는 일은 이런 것입니다. 이런 종류의 코멘트를 읽으면, LLM에서 왔을 때는 현학적이고 짜증나고 성가시다고 느끼지만, 사람에게서 왔을 때는 훨씬 더 환영하게 됩니다.

그래서 버그 분류에 대해 더 생각하면서, 저희는 실제로 두 번째 축을 생각하기 시작했습니다. LLM이 잡을 수 있는 것과 잡을 수 없는 것이 있지만, 인간이 LLM으로부터 받고 싶어하는 것과 받고 싶어하지 않는 것도 있다는 것입니다.

그래서 저희가 한 일은 저희 코드베이스와 오픈소스 코드베이스에서 10,000개의 코멘트를 가져와서 다양한 LLM에 입력하고 분류하도록 요청한 것입니다. 한 번만 한 것이 아니라 꽤 여러 번 했고, 그런 다음 그 코멘트들을 요약했습니다. 결국 저희가 얻은 것은 이 차트였는데, 실제로 실제 코드베이스에서 볼 수 있는 꽤 다양한 종류의 버그가 있다는 것을 보여줍니다. 잠시 LLM을 무시하고 인간에 대해서만 이야기하면요.

버그라고 불리는 것들이 있습니다. 이것들은 코드가 의도하지 않은 방식으로 동작하게 만드는 논리적 불일치입니다. 실수로 커밋된 코드도 있습니다. 이것은 예상보다 더 자주 나타납니다. 성능과 보안 문제가 있습니다. 문서화 문제가 있는데, 코드가 한 가지를 말하고 다른 것을 하면서 어느 쪽이 맞는지 불분명한 경우입니다. 스타일 변경도 있는데, "이 주석을 업데이트해야 해요" 또는 "이 코드베이스에서는 다른 패턴을 따릅니다" 같은 것들입니다.

그리고 오른쪽 상단 사분면 밖에도 많은 것들이 있습니다. 오른쪽 하단에서, 인간은 받고 싶어하지만 LLM이 아직 도달할 수 없는 것들은 부족 지식 같은 것들입니다. PR에서 많이 볼 수 있는 한 종류의 코멘트는 "우리는 예전에 이렇게 했었는데, 이러저러한 이유로 더 이상 이렇게 하지 않아요"입니다. 이 문서는 존재하지 않습니다. 시니어 개발자들의 머릿속에만 존재합니다. 그것은 훌륭하지만 AI가 그것을 읽어내기는 정말 어렵습니다.

왼쪽에서, LLM은 확실히 잡을 수 있지만 인간은 받고 싶어하지 않는 것들은 제가 앞서 보여드린 코드 청결도와 모범 사례입니다. 저희가 발견한 예시들은 "이 함수에 주석을 달아라", "테스트를 추가해라", "이 타입을 다른 타입으로 추출해라", "이 로직을 함수로 추출해라" 같은 것들입니다. 이것을 말하는 것은 항상 맞지만, LLM에 언제 적용해야 하는지 아는 것은 정말 어렵다고 생각합니다. 인간으로서 여러분은 어떤 기준을 적용합니다. "이 코드베이스에서 이 로직은 특히 까다롭고 누군가 걸려 넘어질 것 같으니 추출해야 해" 대 "이 코드베이스에서는 실제로 괜찮아" 같은 것 말입니다. 하지만 봇은 거의 항상 이 코멘트를 남길 수 있습니다. 사실 인간도 거의 항상 이 코멘트를 남길 수 있고 기술적으로는 맞습니다. 문제는 그것이 코드베이스에서 환영받는지 여부입니다.

이 모든 것 밖에서 한 가지 말씀드리고 싶은 것은, 더 많이 추가할수록 사람들이 편안해하는 영역이 더 커지는 것 같다는 것입니다. 하지만 현재로서는 저희가 가진 컨텍스트, 코드베이스, 과거 히스토리, 스타일 가이드와 규칙을 고려할 때, 저희는 가진 것으로 해야 합니다.

그래서 결국 이런 아이디어에 도달했습니다. 이것들이 기본적으로 LLM이 만들 수 있고 인간이 받고 싶어하는 코멘트의 종류라는 것입니다.

이제, LLM으로 작업해 보셨다면, 이런 종류의 오프라인 패스와 첫 번째 패스가 초기 분류에는 훌륭하다는 것을 아실 겁니다. 하지만 훨씬 더 어려운 질문은 계속해서 올바른지 어떻게 아느냐는 것입니다.

이야기가 진행되면서, 저희는 LLM이 남기는 코멘트를 특성화하기 시작했습니다. LLM의 능력 범위 내에 있고 인간이 받고 싶어하는 것들만 프롬프트하도록 프롬프트를 업데이트했습니다. 일화적으로 사람들이 훨씬 더 좋아하기 시작했습니다.

하지만 그런 다음 생각하기 시작했습니다. 이 LLM이 제대로 가고 있는지 어떻게 알 수 있을까? 새로운 LLM들, Claude 4나 Sonnet 대신 Opus에 대해 생각할 때, 저희가 실제로 이 오른쪽 상단 사분면에 머물고 있는지 어떻게 알 수 있을까? 그리고 컨텍스트를 늘릴 때, 이것이 우리에게 커지지 않는다는 것을 어떻게 알 수 있을까? 그리고 실제로 저희가 아직 남기지 않고 있는 더 많은 종류의 코멘트가 있을 수도 있을까?

그래서 우선, 저희는 현재 어떤 종류의 코멘트를 남기고 있는지 살펴보는 것부터 시작했습니다. 결과는 다를 수 있습니다. 저희의 경우, 지금까지 본 것을 기반으로 LLM이 남기는 코멘트의 대략적인 비율은 이렇습니다. 하지만 저희에게 더 깊은 질문은 성공을 어떻게 측정하느냐였습니다. 이 사분면을 고려할 때, 저희가 오른쪽 상단에 있다는 것을 어떻게 알 수 있을까?

첫 번째는 저희에게 쉬웠습니다. LLM이 잡을 수 있는 것과 잡을 수 없는 것에 대해 생각해 보세요. 저희가 시작한 것은 제품에 업보트와 다운보트를 추가하는 것이었습니다. 이 코멘트들에 이모지로 반응할 수 있게 했고, 그것들은 LLM이 환각을 일으킬 때 저희에게 알려줍니다. 다운보트가 급증하기 시작하면, 저희는 이 것의 능력을 넘어서려고 하고 있을 수 있다는 것을 알고 톤을 낮춰야 합니다.

하지만 두 번째는 훨씬 더 어려웠습니다. 인간이 받고 싶어하는 것과 받고 싶어하지 않는 것은 어떻게 알아내야 할지 확실하지 않았습니다. 업보트/다운보트를 구현했고, 요즘 4% 미만의 다운보트 비율을 보고 있습니다. 그것에 대해 꽤 좋게 느꼈습니다.

두 번째에 대해 생각하기 시작하면서 깨달은 것은, 코멘트의 요점이 뭘까요? 코드 리뷰에서 왜 코멘트를 남길까요? 궁극적으로 누군가가 실제로 그것을 반영하여 코드를 업데이트하도록 하기 위해 코드 리뷰에서 코멘트를 남깁니다. 그래서 저희의 질문은, 그것을 측정할 수 있을까? 코멘트의 몇 퍼센트가 실제로 그들이 설명하는 변경으로 이어지는지 측정할 수 있을까?

그래서 저희는 그것을 하기 시작했습니다. 오픈소스 저장소와 Graphite(코드 리뷰 도구)가 접근할 수 있는 다양한 저장소에서 그 숫자를 실제로 측정할 수 있는지 물었습니다. 저희가 발견한 가장 흥미로운 것 중 하나는 인간 코멘트의 약 50%만이 변경으로 이어진다는 것이었습니다.

그래서 저희는 질문하기 시작했습니다. LLM도 최소한 이 정도는 될 수 있을까? 최소한 이 정도가 되면, 최소한 인간 수준의 충실도로 코멘트를 남기는 것이니까요.

청중 중에 앉아서 "근데 왜 100%의 코멘트가 행동으로 이어지지 않는 거죠?"라고 생각하실 수도 있습니다. 이 숫자에 대해 설명을 덧붙이고 싶습니다. 제가 말하는 것은 그 PR 자체 내에서 행동으로 이어지는 것입니다. 많은 코멘트들은 때때로 앞으로 수정됩니다. 사람들이 "알겠어요, 후속 작업에서 고칠게요"라고 하는 경우요. 많은 코멘트들은 또한 "참고로, 나중에 이렇게 하면 이런 다른 방법으로 할 수 있어요, 하지만 지금 당장 행동할 필요는 없어요" 같은 것들입니다. 공정하게 말하면, 그리고 일부는 순전히 선호의 문제입니다. "나라면 이렇게 할 거야". 누군가는 동의하지 않습니다. 건강한 코드 리뷰 문화에서는 그런 불일치의 공간이 존재합니다.

그래서 저희는 이것을 측정하기 시작했고, 봇을 여기에 도달하게 할 수 있는지 물었습니다. 시간이 지나면서 실제로 했습니다. 3월 현재 52%입니다. 이것은 실제로 올바르게 프롬프트하기 시작하면 거기에 도달할 수 있다는 것을 의미합니다.

저희의 더 넓은 테제는 LLM을 통해 버그를 찾는 것이 실제로 작동한다는 것입니다. 이러한 발견들을 프로덕션에서 시도해 보고 싶으시다면, Diamond가 그것을 제공하는 저희 제품입니다. 저기 부스가 있습니다. 감사합니다.

<!-- FULL_TRANSLATION_END -->
