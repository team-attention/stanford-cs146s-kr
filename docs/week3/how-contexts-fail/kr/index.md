---
title: "긴 컨텍스트가 실패하는 방식"
originalTitle: "How Long Contexts Fail"
source_url: "https://www.dbreunig.com/2025/06/22/how-contexts-fail-and-how-to-fix-them.html"
source_type: web
author: "Drew Breunig"
fetch_date: "2026-01-12"
translatedAt: "2026-01-12"
translation_status: complete
---

# 긴 컨텍스트가 실패하는 방식

[원본 링크](https://www.dbreunig.com/2025/06/22/how-contexts-fail-and-how-to-fix-them.html)

**저자:** Drew Breunig
**게시일:** 2025년 6월 22일
**최종 수정:** 2025년 12월 6일

## 개요

이 글에서는 100만 토큰에 달하는 확장된 컨텍스트 윈도우(context window)가 왜 AI 에이전트 성능을 자동으로 향상시키지 못하는지 살펴봅니다. 저자는 컨텍스트가 커지면 문제가 해결되는 것이 아니라 새로운 실패 유형이 발생한다고 주장합니다.

## 핵심 전제

최신 프론티어 모델(frontier model)들은 대규모 컨텍스트 윈도우를 지원하지만, 이를 전부 채우면 오히려 문제가 생깁니다. 저자는 다음과 같이 말합니다: "성공적인 에이전트를 구축하려면 컨텍스트를 잘 관리해야 합니다. 100만 토큰 컨텍스트 윈도우가 있다고 해서 그것을 다 채워야 하는 건 아닙니다."

## 네 가지 컨텍스트 실패 유형

### 1. 컨텍스트 오염 (Context Poisoning)

오류나 환각(hallucination)이 컨텍스트에 남아 반복적으로 참조되면 복합적으로 문제가 발생합니다. Gemini 2.5 포켓몬 사례 연구에서는 에이전트의 목표 섹션에 잘못된 정보가 유입되었을 때 불가능한 전략을 개발하는 현상이 나타났습니다.

### 2. 컨텍스트 산만 (Context Distraction)

컨텍스트가 최적 임계값을 넘어 축적되면, 모델이 훈련된 지식을 활용하는 대신 과거 정보에 과도하게 의존하게 됩니다. Gemini 2.5는 10만 토큰을 초과하면 성능이 저하되어 새로운 전략 대신 반복적인 행동을 선호하는 경향을 보였습니다.

### 3. 컨텍스트 혼란 (Context Confusion)

과도한 정보, 특히 관련 없는 도구 정의들은 모델이 불필요한 데이터를 처리하도록 강제합니다. Berkeley Function-Calling Leaderboard 연구에 따르면 모든 모델이 도구가 많아질수록 성능이 저하되며, 특히 소형 모델은 19개 도구에서 46개 도구로 늘어날 때 극적으로 실패했습니다.

### 4. 컨텍스트 충돌 (Context Clash)

여러 상호작용에 걸쳐 수집된 정보가 서로 모순될 수 있습니다. Microsoft와 Salesforce의 연구에 따르면 정보를 동시에 제시할 때보다 순차적으로 제시할 때 평균 39% 성능이 하락했습니다. OpenAI의 o3 모델은 98.1에서 64.1로 떨어졌습니다.

## 시사점

이러한 실패는 에이전트에 특히 큰 영향을 미칩니다. 에이전트는 바로 이런 조건에서 작동하기 때문입니다: 분산된 정보를 수집하고, 순차적으로 도구를 호출하며, 긴 히스토리를 유지합니다.

---

## 핵심 요약

- 컨텍스트 윈도우가 100만 토큰까지 확장되었지만, 이를 모두 채우면 오히려 성능이 저하됨
- 네 가지 실패 유형: 오염(잘못된 정보 지속), 산만(과거 정보 과의존), 혼란(불필요한 정보 과부하), 충돌(모순된 정보)
- 에이전트는 분산 정보 수집, 순차적 도구 호출, 긴 히스토리 유지 특성상 이러한 실패에 취약함
- 핵심 교훈: 컨텍스트 크기보다 컨텍스트 품질 관리가 중요함
