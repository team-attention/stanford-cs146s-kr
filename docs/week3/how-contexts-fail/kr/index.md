---
title: "긴 컨텍스트가 실패하는 방식"
originalTitle: "How Long Contexts Fail"
author: "Drew Breunig"
sourceUrl: "https://www.dbreunig.com/2025/06/22/how-contexts-fail-and-how-to-fix-them.html"
translatedAt: "2026-01-13"
status: "final"
qaScore:
  consistency: 9
  readability: 8
  accuracy: 9
  overall: 9
---

# 긴 컨텍스트가 실패하는 방식

[원본 링크](https://www.dbreunig.com/2025/06/22/how-contexts-fail-and-how-to-fix-them.html)

컨텍스트 관리가 성공적인 에이전트의 핵심이다

프론티어 모델의 컨텍스트 윈도우가 계속 확장되어, 이제 많은 모델이 최대 100만 토큰을 지원한다. 긴 컨텍스트 윈도우가 우리가 꿈꾸던 에이전트를 실현할 것이라는 기대에 찬 논의가 많다. 결국, 충분히 큰 윈도우만 있으면 필요한 모든 것—도구, 문서, 지침 등—을 프롬프트에 넣고 모델이 나머지를 처리하도록 맡기면 되지 않을까?

긴 컨텍스트는 RAG 열기를 꺾었고(가장 좋은 문서를 찾을 필요 없이 모두 프롬프트에 넣으면 되니까!), MCP 열풍을 촉발했으며(모든 도구에 연결하면 모델이 어떤 작업이든 처리한다!), 에이전트에 대한 기대를 높였다.

하지만 현실에서 더 긴 컨텍스트가 더 나은 응답을 만들어내는 것은 아니다. 컨텍스트를 과부하하면 에이전트와 애플리케이션이 예상치 못한 방식으로 실패할 수 있다. 컨텍스트는 오염되거나, 산만해지거나, 혼란스러워지거나, 충돌할 수 있다. 정보를 수집하고, 발견을 종합하며, 행동을 조율할 때 컨텍스트에 의존하는 에이전트에게 이는 특히 큰 문제다.

컨텍스트가 통제를 벗어나는 방식들을 살펴본 다음, 컨텍스트 실패를 완화하거나 완전히 피하는 방법을 검토해 보자.

## 컨텍스트 실패 유형

- 컨텍스트 오염: 환각이 컨텍스트에 들어갈 때
- 컨텍스트 산만: 컨텍스트가 훈련을 압도할 때
- 컨텍스트 혼란: 불필요한 컨텍스트가 응답에 영향을 줄 때
- 컨텍스트 충돌: 컨텍스트의 일부가 서로 맞지 않을 때

## 컨텍스트 오염

컨텍스트 오염은 환각이나 다른 오류가 컨텍스트에 들어가 반복적으로 참조될 때 발생한다.

딥마인드 팀은 Gemini 2.5 기술 보고서에서 컨텍스트 오염을 지적했다. 포켓몬 게임을 플레이할 때, Gemini 에이전트는 가끔 플레이 중 환각을 일으켜 게임 상태에 대한 잘못된 정보로 컨텍스트를 오염시켰다. 컨텍스트의 "목표" 섹션이 오염되면, 에이전트는 달성할 수 없는 목표를 추구하며 비논리적인 전략을 개발하고 행동을 반복했다.

## 컨텍스트 산만

컨텍스트 산만은 컨텍스트가 너무 길어져서 모델이 컨텍스트에 과도하게 집중하고, 훈련에서 배운 것을 무시할 때 발생한다.

에이전트 워크플로우 중에 컨텍스트가 커지면서—모델이 더 많은 정보를 수집하고 히스토리를 쌓으면서—축적된 컨텍스트가 도움이 되기보다 산만해질 수 있다. 포켓몬을 플레이하는 Gemini 에이전트가 이 문제를 명확히 보여주었다. 컨텍스트가 10만 토큰을 크게 초과하자, 에이전트는 새로운 계획을 세우기보다 방대한 히스토리에서 행동을 반복하는 경향을 보였다. 훈련을 활용해 새로운 전략을 개발하는 대신, 에이전트는 광범위한 컨텍스트 히스토리에서 과거 행동을 반복하는 데 집착했다.

작은 모델의 경우, 산만 임계값은 훨씬 낮다. Databricks 연구에 따르면 Llama 3.1 405b는 약 3만 2천 토큰부터 모델 정확도가 떨어지기 시작했고, 더 작은 모델은 더 일찍 떨어졌다.

컨텍스트 윈도우가 채워지기 훨씬 전에 모델이 오작동하기 시작한다면, 초대형 컨텍스트 윈도우의 의미는 무엇일까? 요약하자면: 요약과 사실 검색이다. 이 두 가지를 하지 않는다면, 선택한 모델의 산만 임계값을 주의해야 한다.

## 컨텍스트 혼란

컨텍스트 혼란은 컨텍스트의 불필요한 내용이 저품질 응답을 생성하는 데 사용될 때 발생한다.

잠시 동안 모든 사람이 MCP를 출시할 것처럼 보였다. 강력한 모델이 모든 서비스와 자료에 연결되어 지루한 작업을 모두 처리하는 꿈이 실현될 것 같았다. 모든 도구 설명을 프롬프트에 넣고 실행하면 된다. Claude의 시스템 프롬프트가 그 방향을 보여주었는데, 대부분 도구 정의나 도구 사용 지침이었다.

하지만 통합과 경쟁이 MCP를 늦추지 않더라도, 컨텍스트 혼란이 그렇게 할 것이다. 도구가 너무 많을 수 있다는 것이 밝혀졌다.

Berkeley Function-Calling Leaderboard는 모델이 프롬프트에 응답할 때 도구를 효과적으로 사용하는 능력을 평가하는 도구 사용 벤치마크다. 리더보드에 따르면 모든 모델이 도구가 하나 이상 제공되면 성능이 저하된다. 또한 Berkeley 팀은 제공된 함수 중 어느 것도 관련이 없는 시나리오를 설계하여 모델 출력이 함수 호출 없이 나와야 한다고 예상했다. 그러나 모든 모델이 때때로 관련 없는 도구를 호출했다.

컨텍스트 혼란의 놀라운 예시는 46개의 서로 다른 도구를 특징으로 하는 GeoEngine 벤치마크에서 소형 모델 성능을 평가한 최근 논문에서 볼 수 있다. 팀이 양자화된 Llama 3.1 8b에 46개 도구 모두와 함께 쿼리를 제공했을 때, 컨텍스트가 16k 컨텍스트 윈도우 내에 충분히 있었음에도 실패했다. 하지만 모델에 19개 도구만 제공했을 때는 성공했다.

문제는 이것이다: 컨텍스트에 무언가를 넣으면 모델은 그것에 주의를 기울여야 한다. 관련 없는 정보나 불필요한 도구 정의일 수 있지만, 모델은 그것을 고려하게 된다. 대형 모델, 특히 추론 모델(reasoning model)은 불필요한 컨텍스트를 무시하거나 버리는 데 더 나아지고 있지만, 쓸모없는 정보가 에이전트를 방해하는 것을 계속 보게 된다. 더 긴 컨텍스트는 더 많은 정보를 넣을 수 있게 해주지만, 이 능력에는 단점이 따른다.

## 컨텍스트 충돌

컨텍스트 충돌은 컨텍스트에 새로운 정보와 도구를 축적할 때 컨텍스트의 다른 정보와 충돌하는 경우다.

이것은 컨텍스트 혼란의 더 심각한 버전이다: 여기서 나쁜 컨텍스트는 관련이 없는 것이 아니라, 프롬프트의 다른 정보와 직접 충돌한다.

Microsoft와 Salesforce 팀이 최근 논문에서 이를 훌륭하게 문서화했다. 팀은 여러 벤치마크에서 프롬프트를 가져와 정보를 여러 프롬프트에 걸쳐 '분할'했다. 때로는 앉아서 ChatGPT나 Claude에 필요한 모든 세부 사항을 고려하며 여러 단락을 입력한 후 엔터를 친다. 다른 때는 간단한 프롬프트로 시작한 다음, 챗봇의 답변이 만족스럽지 않을 때 추가 세부 사항을 덧붙인다. Microsoft/Salesforce 팀은 벤치마크 프롬프트를 이러한 다단계 교환처럼 보이도록 수정했다.

분할된 프롬프트는 극적으로 더 나쁜 결과를 보였으며, 평균 39% 하락했다. 팀은 다양한 모델을 테스트했는데 – OpenAI의 자랑인 o3의 점수는 98.1에서 64.1로 떨어졌다.

무슨 일이 일어나고 있을까? 정보가 한 번에 주어지는 것보다 단계적으로 수집될 때 왜 모델 성능이 더 나빠질까?

답은 컨텍스트 혼란이다: 전체 채팅 교환을 포함하는 조립된 컨텍스트에는 모델이 모든 정보를 갖기 전에 도전에 답하려는 초기 시도가 포함되어 있다. 이러한 잘못된 답변은 컨텍스트에 남아 있고 모델이 최종 답변을 생성할 때 영향을 미친다. 팀은 이렇게 썼다: "LLM은 종종 초기 턴에서 가정을 세우고 조기에 솔루션을 생성하며, 이에 과도하게 의존한다. LLM이 대화에서 잘못된 방향으로 가면, 길을 잃는다."

이것은 에이전트 빌더에게 좋은 조짐이 아니다. 에이전트는 문서, 도구 호출, 그리고 하위 문제를 담당하는 다른 모델에서 컨텍스트를 조립한다. 다양한 소스에서 가져온 이 모든 컨텍스트는 자기 자신과 충돌할 가능성이 있다. 또한, 직접 만들지 않은 MCP 도구에 연결하면 그 설명과 지침이 프롬프트의 나머지 부분과 충돌할 가능성이 더 커진다.

---

100만 토큰 컨텍스트 윈도우의 등장은 변혁적으로 느껴졌다. 에이전트에게 필요한 모든 것을 프롬프트에 넣을 수 있는 능력은 어떤 문서든 접근하고, 모든 도구에 연결하며, 완벽한 기억을 유지하는 초지능 어시스턴트의 비전을 불러일으켰다.

하지만 보았듯이, 더 큰 컨텍스트는 새로운 실패 모드를 만들어낸다. 컨텍스트 오염은 시간이 지나며 복합되는 오류를 심어둔다. 컨텍스트 산만은 에이전트가 컨텍스트에 크게 의존하고 앞으로 나아가기보다 과거 행동을 반복하게 한다. 컨텍스트 혼란은 관련 없는 도구나 문서 사용으로 이어진다. 컨텍스트 충돌은 추론을 탈선시키는 내부 모순을 만들어낸다.

이러한 실패는 에이전트에게 가장 큰 타격을 준다. 에이전트는 바로 컨텍스트가 급증하는 시나리오에서 작동하기 때문이다: 여러 소스에서 정보 수집, 순차적 도구 호출, 다중 턴 추론, 그리고 광범위한 히스토리 축적.

다행히 해결책이 있다! 다음 포스트에서 도구를 동적으로 로드하는 방법부터 컨텍스트 격리를 설정하는 방법까지, 이러한 문제를 완화하거나 피하는 기술을 다루겠다.

---

## 핵심 요약

- 프론티어 모델의 컨텍스트 윈도우가 100만 토큰까지 확장되었지만, 더 긴 컨텍스트가 더 나은 응답을 보장하지는 않는다
- 네 가지 컨텍스트 실패 유형: 오염(환각이 반복 참조됨), 산만(훈련보다 히스토리에 과의존), 혼란(불필요한 정보로 인한 저품질 응답), 충돌(정보 간 모순)
- Gemini 2.5 포켓몬 실험: 10만 토큰 초과 시 성능 저하, 환각으로 인한 목표 오염 확인
- Berkeley 연구: 도구가 많을수록 모델 성능 저하, 46개 도구에서 실패했던 Llama 3.1 8b가 19개 도구에서는 성공
- Microsoft/Salesforce 연구: 정보를 단계적으로 제공 시 평균 39% 성능 하락, o3는 98.1에서 64.1로 급락
- 에이전트는 다중 소스 정보 수집, 순차적 도구 호출, 긴 히스토리 유지로 인해 이러한 실패에 가장 취약하다
- 핵심 교훈: 컨텍스트 크기보다 컨텍스트 품질 관리가 성공적인 에이전트의 핵심이다
