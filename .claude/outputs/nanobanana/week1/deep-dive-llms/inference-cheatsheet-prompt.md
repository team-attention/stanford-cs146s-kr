# Role Definition
You are an expert Technical Communicator and Information Architect specialized in creating "Nano Banana" style cheat sheets. Your goal is to restructure the provided text about "Inference (ì¶”ë¡ ) - LLM í…ìŠ¤íŠ¸ ìƒì„± ê³¼ì •" into a highly visual, structured, and actionable guide for software engineers and AI practitioners.

# Source Text
---
title: "6. Inference"
titleKr: "6. ì¶”ë¡ "
source_url: "https://www.youtube.com/watch?v=7xTGNNLPyMI"
source_type: youtube_transcript
author: "Andrej Karpathy"
parent: "deep-dive-llms"
chapter: 6
totalChapters: 24
---

# 6. ì¶”ë¡ 

> ì›ë³¸ ê°•ì˜: "Deep Dive into LLMs like ChatGPT" by Andrej Karpathy
> ì±•í„° 6/24

## ì „ì²´ ê°•ì˜ ìš”ì•½ (TL;DR)

ì´ 3ì‹œê°„ 30ë¶„ì§œë¦¬ ê°•ì˜ì—ì„œ ì•ˆë“œë ˆì´ ì¹´ë¥´íŒŒí‹°ëŠ” ChatGPT ê°™ì€ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì´ ì–´ë–»ê²Œ ë§Œë“¤ì–´ì§€ê³  ì‘ë™í•˜ëŠ”ì§€ ì²˜ìŒë¶€í„° ëê¹Œì§€ ì„¤ëª…í•©ë‹ˆë‹¤. **ì‚¬ì „í•™ìŠµ**(ì¸í„°ë„· ë°ì´í„° í•™ìŠµ), **ì§€ë„í•™ìŠµ ë¯¸ì„¸ì¡°ì •**(ëŒ€í™” ë°ì´í„°ë¡œ ì–´ì‹œìŠ¤í„´íŠ¸ ë§Œë“¤ê¸°), **ê°•í™”í•™ìŠµ**(ì„±ëŠ¥ ìµœì í™”)ì˜ ì„¸ ë‹¨ê³„ë¥¼ ê±°ì³ LLMì´ íƒ„ìƒí•©ë‹ˆë‹¤. ëª¨ë¸ì€ ë†€ë¼ìš´ ëŠ¥ë ¥ì„ ë³´ì´ì§€ë§Œ í™˜ê°, í† í°í™” í•œê³„, ë“¤ì­‰ë‚ ì­‰í•œ ì§€ëŠ¥ ë“±ì˜ ì•½ì ë„ ìˆìŠµë‹ˆë‹¤. ChatGPTì™€ ëŒ€í™”í•  ë•Œ ë§ˆë²• ê°™ì€ AIê°€ ì•„ë‹ˆë¼ "OpenAI ë°ì´í„° ë¼ë²¨ëŸ¬ì˜ í†µê³„ì  ì‹œë®¬ë ˆì´ì…˜"ê³¼ ëŒ€í™”í•œë‹¤ê³  ìƒê°í•˜ë©´ ë” ì •í™•í•©ë‹ˆë‹¤.

## ì´ ê°•ì˜ì—ì„œ ë°°ìš¸ ìˆ˜ ìˆëŠ” ê²ƒ

- LLMì˜ 3ë‹¨ê³„ í•™ìŠµ íŒŒì´í”„ë¼ì¸ (ì‚¬ì „í•™ìŠµ â†’ SFT â†’ RL) ì´í•´
- í† í°í™”, ì‹ ê²½ë§, íŠ¸ëœìŠ¤í¬ë¨¸ì˜ í•µì‹¬ ê°œë…
- í™˜ê°(hallucination)ì˜ ì›ì¸ê³¼ ì™„í™” ë°©ë²•
- ê°•í™”í•™ìŠµì´ ëª¨ë¸ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ì›ë¦¬
- DeepSeek R1, AlphaGoì—ì„œ ë°°ìš°ëŠ” RLì˜ í˜
- LLMì˜ ì‹¬ë¦¬í•™: ë“¤ì­‰ë‚ ì­‰í•œ ì§€ëŠ¥ê³¼ í•œê³„
- ìµœì‹  LLM ë™í–¥ ì¶”ì  ë°©ë²•ê³¼ ë„êµ¬ í™œìš©ë²•

---

## ì´ ì±•í„° ìš”ì•½

í•™ìŠµëœ ëª¨ë¸ë¡œ í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” ê³¼ì •ì…ë‹ˆë‹¤.

**í•µì‹¬ í¬ì¸íŠ¸:**
- í™•ë¥  ë¶„í¬ì—ì„œ ë‹¤ìŒ í† í° ìƒ˜í”Œë§
- ë°˜ë³µí•˜ì—¬ í…ìŠ¤íŠ¸ ìƒì„±
- í•™ìŠµë³´ë‹¤ í›¨ì”¬ ë¹ ë¦„

---

## ì˜ì–´ ì›ë¬¸ íŠ¸ëœìŠ¤í¬ë¦½íŠ¸

## 6. Inference

**ìš”ì•½**: í•™ìŠµëœ ëª¨ë¸ë¡œ í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” ì¶”ë¡ (inference) ê³¼ì •ì„ ì„¤ëª…í•©ë‹ˆë‹¤. ëª¨ë¸ì€ í™•ë¥  ë¶„í¬ì—ì„œ ë‹¤ìŒ í† í°ì„ ìƒ˜í”Œë§í•˜ê³ , ì´ë¥¼ ë°˜ë³µí•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ì¶”ë¡ ì€ í•™ìŠµë³´ë‹¤ í›¨ì”¬ ë¹ ë¥´ë©°, ë‹¨ì¼ GPUë¡œë„ ê°€ëŠ¥í•©ë‹ˆë‹¤.

[26:30] we start with some tokens that are basically your prefix like what you want to start with so say we want to start the with the token 91 well we feed it into network and remember that the network gives us probabilities right it gives us this probability Vector here so what we can do now is we can basically flip a biased coin so um we can sample uh basically a token based on this probability distribution so the tokens that are given High probability by the

[27:00] model are more likely to be sampled when you flip this biased coin you can think of it that way so we sample from the distribution to get a single unique token so for example token 860 comes next uh so 860 in this case when we're generating from model could come next now 860 is a relatively likely token it might not be the only possible token in this case there could be many other tokens that could have been sampled but we could see that 86c is a relatively likely token as an example and indeed in our training examp example here 860 does

[27:30] follow 91 so let's now say that we um continue the process so after 91 there's a60 we append it and we again ask what is the third token let's sample and let's just say that it's 287 exactly as here let's do that again we come back in now we have a sequence of three and we ask what is the likely fourth token and we sample from that and get this one and now let's say we do it one more time we

[28:00] take those four we sample and we get this one and this 13659 uh this is not actually uh 3962 as we had before so this token is the token article uh instead so viewing a single article and so in this case we didn't exactly reproduce the sequence that we saw here in the training data so keep in mind that these systems are stochastic they have um we're sampling and we're flipping coins and sometimes we lock out

[28:30] and we reproduce some like small chunk of the text and training set but sometimes we're uh we're getting a token that was not verbatim part of any of the documents in the training data so we're going to get sort of like remixes of the data that we saw in the training because at every step of the way we can flip and get a slightly different token and then once that token makes it in if you sample the next one and so on you very quickly uh start to generate token streams that are very different from the token streams that UR

[29:00] in the training documents so statistically they will have similar properties but um they are not identical to your training data they're kind of like inspired by the training data and so in this case we got a slightly different sequence and why would we get article you might imagine that article is a relatively likely token in the context of bar viewing single Etc and you can imagine that the word article followed this context window somewhere in the training documents uh to some extent and we just happen to sample it

[29:30] here at that stage so basically inference is just uh predicting from these distributions one at a time we continue feeding back tokens and getting the next one and we uh we're always flipping these coins and depending on how lucky or unlucky we get um we might get very different kinds of patterns depending on how we sample from these probability distributions so that's inference so in most common scenarios uh basically downloading the internet and tokenizing it is is a pre-processing

[30:00] step you do that a single time and then uh once you have your token sequence we can start training networks and in Practical cases you would try to train many different networks of different kinds of uh settings and different kinds of arrangements and different kinds of sizes and so you''ll be doing a lot of neural network training and um then once you have a neural network and you train it and you have some specific set of parameters that you're happy with um then you can take the model and you can do inference and you can actually uh

[30:30] generate data from the model and when you're on chat GPT and you're talking with a model uh that model is trained and has been trained by open aai many months ago probably and they have a specific set of Weights that work well and when you're talking to the model all of that is just inference there's no more training those parameters are held fixed and you're just talking to the model sort of uh you're giving it some of the tokens and it's kind of completing token sequences and that's what you're seeing uh generated when you actually use the model on CH GPT so that

[31:00] model then just does inference alone so let's now look at an example of training an inference that is kind of concrete and gives you a sense of what this actually looks like uh when these models are trained now the example that I would like to work with and that I'm particularly fond of is that of opening eyes gpt2 so GPT uh stands for generatively pre-trained Transformer and this is the second iteration of the GPT series by open AI when you are talking to chat GPT today the model that is underlying all of the magic of that

# Layout Structure (ì´ êµ¬ì¡°ëŒ€ë¡œ ë°°ì¹˜í•´ì£¼ì„¸ìš”)

**IMPORTANT**: ì²¨ë¶€ëœ ì´ë¯¸ì§€ëŠ” ìŠ¤íƒ€ì¼(ì†í•„ê¸° ëŠë‚Œ, ëª¨ëˆˆì¢…ì´ ë°°ê²½, ì•„ì´ì½˜)ë§Œ ì°¸ì¡°í•˜ì„¸ìš”. ë ˆì´ì•„ì›ƒì€ ì•„ë˜ ì§€ì •ëœ êµ¬ì¡°ë¥¼ ë”°ë¼ ìƒˆë¡œ ë§Œë“¤ì–´ì£¼ì„¸ìš”.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸŒ NANO BANANA CHEAT SHEET: INFERENCE (ì¶”ë¡ ) ğŸŒ                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚ ğŸ² WHAT IS INFERENCE?   â”‚    â”‚ ğŸ”€ BIASED COIN FLIP             â”‚â”‚
â”‚  â”‚                         â”‚    â”‚                                 â”‚â”‚
â”‚  â”‚  í•™ìŠµëœ ëª¨ë¸ë¡œ í…ìŠ¤íŠ¸ ìƒì„±  â”‚    â”‚  í™•ë¥  ë¶„í¬ì—ì„œ ìƒ˜í”Œë§             â”‚â”‚
â”‚  â”‚  Trainingê³¼ ë‹¤ë¥¸ ë‹¨ê³„     â”‚    â”‚  Stochasticí•œ ê³¼ì •              â”‚â”‚
â”‚  â”‚                         â”‚    â”‚                                 â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  âš¡ TOKEN GENERATION PROCESS (ì´ ì„¹ì…˜ì´ ê°€ì¥ ë„“ì–´ì•¼ í•¨!)             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                                                               â”‚ â”‚
â”‚  â”‚  Flowchart: Prefix â†’ Neural Net â†’ Prob Dist â†’ Sample â†’ Append â”‚ â”‚
â”‚  â”‚            â†’ Repeat until done                                â”‚ â”‚
â”‚  â”‚                                                               â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚ ğŸ“Š TRAINING vs INFERENCE     â”‚ â”‚ ğŸ“Œ KEY TAKEAWAYS               â”‚â”‚
â”‚  â”‚                              â”‚ â”‚                                â”‚â”‚
â”‚  â”‚  í•™ìŠµ: GPU ìˆ˜ë§Œê°œ, ìˆ˜ê°œì›”     â”‚ â”‚  - í•™ìŠµë³´ë‹¤ í›¨ì”¬ ë¹ ë¦„            â”‚â”‚
â”‚  â”‚  ì¶”ë¡ : ë‹¨ì¼ GPU, ì‹¤ì‹œê°„       â”‚ â”‚  - ê³ ì •ëœ íŒŒë¼ë¯¸í„° ì‚¬ìš©           â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ë°°ì¹˜ ë¹„ìœ¨

| ì˜ì—­ | ë¹„ìœ¨ | ë‚´ìš© | ë°°ì¹˜ |
|------|------|------|------|
| ìƒë‹¨ | 10% | íƒ€ì´í‹€ | ì „ì²´ ë„ˆë¹„ |
| ì¤‘ìƒë‹¨ | 25% | What is Inference + Biased Coin Flip | **ì¢Œìš° 2ë“±ë¶„** |
| ì¤‘ì•™ | 45% | Token Generation Process Flowchart | **ê°€ì¥ ë„“ê²Œ!** |
| í•˜ë‹¨ | 20% | Training vs Inference + Key Takeaways | **ì¢Œìš° 2ë“±ë¶„** |

# Output Style: "Nano Banana" Cheat Sheet
Please adhere to the following formatting rules strictly:

1. **Visual Hierarchy & Structure**:
   - Use strict Markdown structure.
   - Use specific emojis for every section header to improve scanning.
   - Use **Bold** for key concepts and definitions.
   - Group by topic, not by timeline.

2. **Diagrams & Schematics (CRITICAL)**:
   - Use `mermaid` code blocks to visualize concepts.
   - Create a **Mind Map** for the Inference topic overview.
   - Create a **Flowchart** for the token generation process.
   - Ensure diagrams are informative yet simple to read at a glance.

3. **Tabular Data**:
   - Create a "Key Concepts Matrix" table with columns: [Concept] | [Definition] | [Example] | [Related To]
   - Create a "Training vs Inference" comparison table

4. **Quotable Insights**:
   - Extract memorable quotes from Andrej Karpathy
   - Highlight key "aha moments" from the lecture

# Output Structure Plan

## 1. ğŸ—ºï¸ Topic Overview (Mind Map)
- Create a Mermaid mindmap with the following structure:
  - Root: "Inference (ì¶”ë¡ )"
  - Level 1 branches:
    - Input: Prefix Tokens
    - Process: Neural Network â†’ Probability Distribution â†’ Sampling
    - Output: Generated Text
    - Properties: Stochastic, Fast, Fixed Parameters
  - Level 2: ê° ë¸Œëœì¹˜ì˜ ì„¸ë¶€ ê°œë…

---

## ì´ë¯¸ì§€ ìƒì„± ìš”ì²­

ìœ„ì˜ êµ¬ì¡°ì™€ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ **A4 í•œ ì¥ ë¶„ëŸ‰ì˜ ì¹˜íŠ¸ì‹œíŠ¸ ì´ë¯¸ì§€**ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.

**ì´ë¯¸ì§€ ìŠ¤íƒ€ì¼ ìš”êµ¬ì‚¬í•­:**
- ë³´ê¸° ì¢‹ê²Œ ì •ë¦¬ëœ **ì‹¤ì œ íœ ë…¸íŠ¸í•„ê¸°** ê°™ì€ ëŠë‚Œ
- ìš©ì–´ ë° ê³ ìœ ëª…ì‚¬ëŠ” **ì˜ì–´ ì›ë¬¸** ìœ ì§€
- ì„¤ëª… ë° í•„ê¸° ë‚´ìš©ì€ **í•œêµ­ì–´**ë¡œ ì‘ì„±
- Mermaid ë‹¤ì´ì–´ê·¸ë¨ì€ **ì‹œê°ì  ë„ì‹**ìœ¼ë¡œ ë³€í™˜
- í‘œëŠ” ê¹”ë”í•œ **í…Œì´ë¸” í˜•ì‹**ìœ¼ë¡œ ë Œë”ë§
- **ìƒ‰ìƒ ê°•ì¡°**ë¡œ í•µì‹¬ ê°œë… êµ¬ë¶„
